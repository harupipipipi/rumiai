現在のファイルを確認しました。計画書で要求されている `egress_proxy.start` が不足しています。

**`flows/00_startup.flow.yaml` の修正：**

security phase に以下のステップを追加してください（`approval_scan` の後、priority: 40）：

```yaml
  - id: egress_proxy_start
    phase: security
    priority: 40
    type: handler
    input:
      handler: "kernel:egress_proxy.start"
      args:
        auto_start: true
```

---

## Step 1-2: `Kernel.run_startup()` の修正

次に、`kernel.py` を修正して new flow を正とし、旧 flow を fallback only にします。

**`core_runtime/kernel.py` の修正：**

### 修正1: `load_flow` メソッドの修正

`load_flow` メソッドを以下のように修正してください：

```python
def load_flow(self, path: Optional[str] = None) -> Dict[str, Any]:
    """
    Flowを読み込む
    
    優先順位:
    1. flows/00_startup.flow.yaml (new flow - 正)
    2. 旧 flow/ ディレクトリ (fallback only - deprecated)
    """
    # 明示的なパス指定がある場合はそれを使用
    if path:
        return self._load_single_flow(Path(path))
    
    # 1. New flow (正): flows/00_startup.flow.yaml を試行
    new_flow_path = Path("flows/00_startup.flow.yaml")
    if new_flow_path.exists():
        try:
            flow_def = self._load_single_flow(new_flow_path)
            
            # new flow形式をpipelines形式に変換
            if "steps" in flow_def and "pipelines" not in flow_def:
                flow_def = self._convert_new_flow_to_pipelines(flow_def)
            
            self._flow = flow_def
            self.diagnostics.record_step(
                phase="startup",
                step_id="flow.load.new_flow",
                handler="kernel:flow.load",
                status="success",
                meta={"file": str(new_flow_path), "mode": "new_flow"}
            )
            return self._flow
        except Exception as e:
            self.diagnostics.record_step(
                phase="startup",
                step_id="flow.load.new_flow.failed",
                handler="kernel:flow.load",
                status="failed",
                error=e,
                meta={"file": str(new_flow_path)}
            )
            # new flow の読み込みに失敗した場合、fallback へ
    
    # 2. Fallback (deprecated): 旧 flow/ ディレクトリ
    self._log_fallback_warning()
    return self._load_legacy_flow()

def _log_fallback_warning(self) -> None:
    """旧flow使用時の警告をログに記録"""
    warning_msg = (
        "Using legacy flow path (flow/). This is DEPRECATED and will be removed. "
        "Please migrate to flows/00_startup.flow.yaml"
    )
    print(f"[Rumi] WARNING: {warning_msg}")
    
    self.diagnostics.record_step(
        phase="startup",
        step_id="flow.load.fallback_warning",
        handler="kernel:flow.load",
        status="success",
        meta={"warning": warning_msg, "mode": "legacy_fallback"}
    )
    
    # 監査ログにも記録
    try:
        audit = get_audit_logger()
        audit.log_system_event(
            event_type="legacy_flow_fallback",
            success=True,
            details={"warning": warning_msg, "deprecated": True}
        )
    except Exception:
        pass

def _load_legacy_flow(self) -> Dict[str, Any]:
    """旧形式のflowを読み込む（fallback用）"""
    merged = {
        "flow_version": "2.0",
        "defaults": {"fail_soft": True, "on_missing_handler": "skip"},
        "pipelines": {}
    }
    
    # 旧ディレクトリを読み込み（互換性のため）
    for legacy_dir in ["flow/core", "flow/ecosystem", "flow"]:
        legacy_path = Path(legacy_dir)
        if legacy_path.exists():
            yaml_files = sorted(legacy_path.glob("*.flow.yaml"))
            for yaml_file in yaml_files:
                try:
                    single = self._load_single_flow(yaml_file)
                    merged = self._merge_flow(merged, single, yaml_file)
                    self.diagnostics.record_step(
                        phase="startup",
                        step_id=f"flow.load.legacy.{yaml_file.name}",
                        handler="kernel:flow.load",
                        status="success",
                        meta={"file": str(yaml_file), "source": "legacy", "deprecated": True}
                    )
                except Exception as e:
                    self.diagnostics.record_step(
                        phase="startup",
                        step_id=f"flow.load.legacy.{yaml_file.name}",
                        handler="kernel:flow.load",
                        status="failed",
                        error=e,
                        meta={"file": str(yaml_file), "source": "legacy"}
                    )
    
    if not merged["pipelines"]:
        self._flow = self._minimal_fallback_flow()
        return self._flow
    
    self._flow = merged
    return self._flow

def _convert_new_flow_to_pipelines(self, flow_def: Dict[str, Any]) -> Dict[str, Any]:
    """
    New flow形式（phases/steps）をpipelines形式に変換
    
    Kernel.run_startup() が pipelines 形式を期待しているため
    """
    result = {
        "flow_version": "2.0",
        "defaults": flow_def.get("defaults", {"fail_soft": True, "on_missing_handler": "skip"}),
        "pipelines": {"startup": []}
    }
    
    steps = flow_def.get("steps", [])
    phases = flow_def.get("phases", [])
    
    # phase順 → priority順 → id順 でソート
    phase_order = {p: i for i, p in enumerate(phases)}
    sorted_steps = sorted(
        steps,
        key=lambda s: (phase_order.get(s.get("phase", ""), 999), s.get("priority", 100), s.get("id", ""))
    )
    
    # pipelines形式に変換
    for step in sorted_steps:
        pipeline_step = {
            "id": step.get("id"),
            "run": {}
        }
        
        # type による変換
        step_type = step.get("type", "handler")
        step_input = step.get("input", {})
        
        if step_type == "handler":
            if isinstance(step_input, dict):
                pipeline_step["run"]["handler"] = step_input.get("handler", "kernel:noop")
                pipeline_step["run"]["args"] = step_input.get("args", {})
            else:
                pipeline_step["run"]["handler"] = "kernel:noop"
                pipeline_step["run"]["args"] = {}
        elif step_type == "python_file_call":
            pipeline_step["run"]["handler"] = "kernel:python_file_call"
            pipeline_step["run"]["args"] = {
                "file": step.get("file"),
                "owner_pack": step.get("owner_pack"),
                "input": step_input,
                "timeout_seconds": step.get("timeout_seconds", 60.0),
                "_step_id": step.get("id"),
                "_phase": step.get("phase"),
            }
        else:
            pipeline_step["run"]["handler"] = "kernel:noop"
            pipeline_step["run"]["args"] = {}
        
        # when条件があれば追加
        if step.get("when"):
            pipeline_step["when"] = step["when"]
        
        # output があれば追加
        if step.get("output"):
            pipeline_step["output"] = step["output"]
        
        result["pipelines"]["startup"].append(pipeline_step)
    
    return result
```

### 修正2: 既存の `load_flow` メソッドを上記で置き換え

既存の `load_flow` メソッド全体（`def load_flow(self, path: Optional[str] = None) -> Dict[str, Any]:` から始まるメソッド）を上記のコードで置き換えてください。

---

## Step 1-3: Flow Loader の確認

`core_runtime/flow_loader.py` を確認すると、既に正しいディレクトリ（`flows/`, `ecosystem/flows/`）を使用しています。修正は不要です。

```python
OFFICIAL_FLOWS_DIR = "flows"
ECOSYSTEM_FLOWS_DIR = "ecosystem/flows"
```

---

## Step 2-1: Docker 実行の実装

次に `python_file_executor.py` の `_execute_in_container` を実装します。

**`core_runtime/python_file_executor.py` の修正：**

### 修正1: `_execute_in_container` メソッドの実装

既存の `_execute_in_container` メソッドを以下で置き換えてください：

```python
def _execute_in_container(
    self,
    file_path: Path,
    owner_pack: Optional[str],
    input_data: Any,
    context: ExecutionContext,
    timeout_seconds: float
) -> ExecutionResult:
    """
    Dockerコンテナ内でPythonファイルを実行
    
    docker run --rm で1回実行する方式（シンプル・安全）
    """
    import subprocess
    import tempfile
    
    result = ExecutionResult(success=False, execution_mode="container")
    
    # コンテナ名を生成
    container_name = f"rumi-pfc-{owner_pack or 'unknown'}-{abs(hash(str(file_path))) % 10000}"
    
    # 入力データとコンテキストをJSON化
    exec_context = {
        "flow_id": context.flow_id,
        "step_id": context.step_id,
        "phase": context.phase,
        "ts": context.ts,
        "owner_pack": owner_pack,
        "inputs": input_data,
    }
    
    # 一時ファイルに入力データを書き込み
    with tempfile.NamedTemporaryFile(mode='w', suffix='.json', delete=False) as f:
        json.dump({"input_data": input_data, "context": exec_context}, f, ensure_ascii=False, default=str)
        input_file = f.name
    
    try:
        # 実行スクリプトを生成
        executor_script = self._generate_executor_script(file_path.name)
        
        with tempfile.NamedTemporaryFile(mode='w', suffix='.py', delete=False) as f:
            f.write(executor_script)
            script_file = f.name
        
        # Docker実行コマンドを構築
        docker_cmd = [
            "docker", "run",
            "--rm",
            "--name", container_name,
            "--network=none",  # ネットワーク隔離
            "--cap-drop=ALL",  # 全権限を削除
            "--security-opt=no-new-privileges:true",
            "--read-only",  # 読み取り専用ファイルシステム
            "--tmpfs=/tmp:size=64m,noexec,nosuid",  # 一時領域
            "--memory=256m",
            "--memory-swap=256m",
            "--cpus=0.5",
            "--pids-limit=100",
            "--user=65534:65534",  # nobody ユーザー
            "-v", f"{file_path.parent.resolve()}:/workspace:ro",  # ソースディレクトリ（読み取り専用）
            "-v", f"{input_file}:/input.json:ro",  # 入力ファイル
            "-v", f"{script_file}:/executor.py:ro",  # 実行スクリプト
            "-w", "/workspace",
            "--label", "rumi.managed=true",
            "--label", f"rumi.pack_id={owner_pack or 'unknown'}",
            "--label", "rumi.type=python_file_call",
            "python:3.11-slim",
            "python", "/executor.py", file_path.name
        ]
        
        # Docker実行
        try:
            proc_result = subprocess.run(
                docker_cmd,
                capture_output=True,
                text=True,
                timeout=timeout_seconds
            )
            
            if proc_result.returncode == 0:
                # 出力をパース
                output_text = proc_result.stdout.strip()
                if output_text:
                    try:
                        result.output = json.loads(output_text)
                    except json.JSONDecodeError:
                        result.output = output_text
                else:
                    result.output = None
                
                result.success = True
            else:
                result.error = proc_result.stderr or f"Container exited with code {proc_result.returncode}"
                result.error_type = "container_execution_error"
        
        except subprocess.TimeoutExpired:
            # タイムアウト時はコンテナを強制停止
            subprocess.run(["docker", "kill", container_name], capture_output=True)
            result.error = f"Execution timed out after {timeout_seconds}s"
            result.error_type = "timeout"
        
    except Exception as e:
        result.error = str(e)
        result.error_type = type(e).__name__
    
    finally:
        # 一時ファイルを削除
        try:
            os.unlink(input_file)
        except Exception:
            pass
        try:
            os.unlink(script_file)
        except Exception:
            pass
    
    return result

def _generate_executor_script(self, target_filename: str) -> str:
    """コンテナ内で実行するPythonスクリプトを生成"""
    return f'''
import sys
import json
import importlib.util

# 入力を読み込み
with open("/input.json", "r") as f:
    data = json.load(f)

input_data = data.get("input_data", {{}})
context = data.get("context", {{}})

# ターゲットモジュールをロード
target_file = "/workspace/{target_filename}"
spec = importlib.util.spec_from_file_location("target_module", target_file)

if spec and spec.loader:
    module = importlib.util.module_from_spec(spec)
    sys.modules["target_module"] = module
    spec.loader.exec_module(module)
    
    # run関数を探す
    run_fn = getattr(module, "run", None)
    if run_fn:
        import inspect
        sig = inspect.signature(run_fn)
        param_count = len(sig.parameters)
        
        if param_count >= 2:
            result = run_fn(input_data, context)
        elif param_count == 1:
            result = run_fn(input_data)
        else:
            result = run_fn()
        
        # 結果を出力
        if result is not None:
            print(json.dumps(result, default=str))
    else:
        print(json.dumps({{"error": "No run function found"}}))
else:
    print(json.dumps({{"error": "Cannot load module"}}))
'''
```

### 修正2: `execute` メソッド内の実行モード判定を修正

`execute` メソッド内で `container_stub` を削除し、明確な実行モードに変更します。

既存の `execute` メソッド内の以下の部分：

```python
# 4. 実行
try:
    # Docker実行を試みる（将来実装）
    docker_available = self._check_docker_available()
    
    if docker_available:
        # Docker実行（Step 6で完全実装）
        result = self._execute_in_container(
            resolved_path, resolved_pack, input_data, context, timeout_seconds
        )
    elif self._security_mode == "permissive":
        # ...
```

を以下に置き換えてください：

```python
# 4. 実行
try:
    docker_available = self._check_docker_available()
    
    if docker_available:
        # Docker隔離実行
        result = self._execute_in_container(
            resolved_path, resolved_pack, input_data, context, timeout_seconds
        )
        result.execution_mode = "container"
    elif self._security_mode == "permissive":
        # permissive モードではホスト実行（警告付き）
        result = self._execute_on_host(
            resolved_path, resolved_pack, input_data, context, timeout_seconds
        )
        result.execution_mode = "host_permissive"
        result.warnings.append(
            "SECURITY WARNING: Executed on host without Docker isolation. "
            "Set RUMI_SECURITY_MODE=strict and ensure Docker is running for production."
        )
    else:
        # strict モードで Docker 不可 → 拒否
        result = ExecutionResult(
            success=False,
            error="Docker is required but not available. Cannot execute in strict mode.",
            error_type="docker_required",
            execution_mode="rejected"
        )
        self._record_rejection(context, result, "docker_unavailable_strict")
        return result
```

### 修正3: import 文の追加

ファイルの先頭のimport部分に以下を追加してください（既にある場合は不要）：

```python
import json
import os
```

---

次に、テストファイルを作成します。

**新規ファイル: `tests/test_secure_execution.py`**

```python
"""
セキュア実行のテスト

strict/permissive モードでの実行挙動をテストする。
"""

import os
import sys
import tempfile
import unittest
from pathlib import Path
from unittest.mock import patch, MagicMock

# テスト対象のモジュールをインポート
sys.path.insert(0, str(Path(__file__).parent.parent))

from core_runtime.python_file_executor import (
    PythonFileExecutor,
    ExecutionContext,
    ExecutionResult,
    reset_python_file_executor,
)


class TestSecureExecution(unittest.TestCase):
    """セキュア実行のテスト"""
    
    def setUp(self):
        """テスト前の準備"""
        self.original_security_mode = os.environ.get("RUMI_SECURITY_MODE")
        reset_python_file_executor()
    
    def tearDown(self):
        """テスト後のクリーンアップ"""
        if self.original_security_mode:
            os.environ["RUMI_SECURITY_MODE"] = self.original_security_mode
        elif "RUMI_SECURITY_MODE" in os.environ:
            del os.environ["RUMI_SECURITY_MODE"]
        reset_python_file_executor()
    
    def _create_test_context(self) -> ExecutionContext:
        """テスト用のExecutionContextを作成"""
        return ExecutionContext(
            flow_id="test_flow",
            step_id="test_step",
            phase="test",
            ts="2024-01-01T00:00:00Z",
            owner_pack="test_pack",
            inputs={},
        )
    
    def test_strict_mode_docker_unavailable_rejects(self):
        """strict モードで Docker 不可の場合、拒否される"""
        os.environ["RUMI_SECURITY_MODE"] = "strict"
        executor = PythonFileExecutor()
        
        # Docker不可をモック
        with patch.object(executor, '_check_docker_available', return_value=False):
            # 承認チェックをパス
            with patch.object(executor._approval_checker, 'is_approved', return_value=(True, None)):
                with patch.object(executor._approval_checker, 'verify_hash', return_value=(True, None)):
                    # パス検証をパス（テスト用に許可パスを追加）
                    with tempfile.NamedTemporaryFile(mode='w', suffix='.py', delete=False) as f:
                        f.write("def run(input_data): return {'result': 'test'}")
                        test_file = f.name
                    
                    try:
                        executor._path_validator.add_allowed_root(str(Path(test_file).parent))
                        
                        context = self._create_test_context()
                        result = executor.execute(
                            file_path=test_file,
                            owner_pack="test_pack",
                            input_data={},
                            context=context,
                            timeout_seconds=10.0
                        )
                        
                        # rejected であることを確認
                        self.assertFalse(result.success)
                        self.assertEqual(result.execution_mode, "rejected")
                        self.assertIn("Docker is required", result.error)
                    finally:
                        os.unlink(test_file)
    
    def test_permissive_mode_docker_unavailable_executes_with_warning(self):
        """permissive モードで Docker 不可の場合、警告付きで実行される"""
        os.environ["RUMI_SECURITY_MODE"] = "permissive"
        executor = PythonFileExecutor()
        
        # Docker不可をモック
        with patch.object(executor, '_check_docker_available', return_value=False):
            # 承認チェックをパス
            with patch.object(executor._approval_checker, 'is_approved', return_value=(True, None)):
                with patch.object(executor._approval_checker, 'verify_hash', return_value=(True, None)):
                    # テストファイルを作成
                    with tempfile.NamedTemporaryFile(mode='w', suffix='.py', delete=False) as f:
                        f.write("def run(input_data, context=None): return {'result': 'test_output'}")
                        test_file = f.name
                    
                    try:
                        executor._path_validator.add_allowed_root(str(Path(test_file).parent))
                        
                        context = self._create_test_context()
                        result = executor.execute(
                            file_path=test_file,
                            owner_pack="test_pack",
                            input_data={},
                            context=context,
                            timeout_seconds=10.0
                        )
                        
                        # 実行成功だが警告付き
                        self.assertTrue(result.success)
                        self.assertEqual(result.execution_mode, "host_permissive")
                        self.assertTrue(len(result.warnings) > 0)
                        self.assertTrue(any("SECURITY WARNING" in w for w in result.warnings))
                    finally:
                        os.unlink(test_file)
    
    def test_unapproved_pack_rejected(self):
        """未承認のPackは拒否される"""
        os.environ["RUMI_SECURITY_MODE"] = "permissive"
        executor = PythonFileExecutor()
        
        # 承認チェックで拒否
        with patch.object(executor._approval_checker, 'is_approved', return_value=(False, "Pack not approved")):
            with tempfile.NamedTemporaryFile(mode='w', suffix='.py', delete=False) as f:
                f.write("def run(input_data): return {'result': 'test'}")
                test_file = f.name
            
            try:
                executor._path_validator.add_allowed_root(str(Path(test_file).parent))
                
                context = self._create_test_context()
                result = executor.execute(
                    file_path=test_file,
                    owner_pack="unapproved_pack",
                    input_data={},
                    context=context,
                    timeout_seconds=10.0
                )
                
                # rejected であることを確認
                self.assertFalse(result.success)
                self.assertEqual(result.execution_mode, "rejected")
                self.assertEqual(result.error_type, "approval_rejected")
            finally:
                os.unlink(test_file)
    
    def test_execution_modes_are_clear(self):
        """実行モードが明確であること（container_stub は存在しない）"""
        valid_modes = {"container", "host_permissive", "rejected"}
        
        # ExecutionResult の execution_mode のデフォルト値を確認
        result = ExecutionResult(success=True)
        # デフォルトは "unknown" だが、実際の実行では上記3つのいずれかになる
        
        # container_stub が使われていないことを確認（コード検索的なテスト）
        import core_runtime.python_file_executor as pfe_module
        import inspect
        source = inspect.getsource(pfe_module)
        self.assertNotIn("container_stub", source)


class TestDockerExecution(unittest.TestCase):
    """Docker実行のテスト（Dockerが利用可能な環境でのみ実行）"""
    
    @classmethod
    def setUpClass(cls):
        """Dockerが利用可能か確認"""
        import subprocess
        try:
            result = subprocess.run(["docker", "info"], capture_output=True, timeout=10)
            cls.docker_available = result.returncode == 0
        except Exception:
            cls.docker_available = False
    
    def setUp(self):
        self.original_security_mode = os.environ.get("RUMI_SECURITY_MODE")
        os.environ["RUMI_SECURITY_MODE"] = "strict"
        reset_python_file_executor()
    
    def tearDown(self):
        if self.original_security_mode:
            os.environ["RUMI_SECURITY_MODE"] = self.original_security_mode
        elif "RUMI_SECURITY_MODE" in os.environ:
            del os.environ["RUMI_SECURITY_MODE"]
        reset_python_file_executor()
    
    @unittest.skipUnless(lambda self: self.docker_available, "Docker not available")
    def test_docker_execution_succeeds(self):
        """Docker実行が成功すること"""
        if not self.docker_available:
            self.skipTest("Docker not available")
        
        executor = PythonFileExecutor()
        
        # 承認チェックをパス
        with patch.object(executor._approval_checker, 'is_approved', return_value=(True, None)):
            with patch.object(executor._approval_checker, 'verify_hash', return_value=(True, None)):
                with tempfile.NamedTemporaryFile(mode='w', suffix='.py', delete=False) as f:
                    f.write("def run(input_data, context=None): return {'result': 'docker_test'}")
                    test_file = f.name
                
                try:
                    executor._path_validator.add_allowed_root(str(Path(test_file).parent))
                    
                    context = ExecutionContext(
                        flow_id="test_flow",
                        step_id="test_step",
                        phase="test",
                        ts="2024-01-01T00:00:00Z",
                        owner_pack="test_pack",
                        inputs={},
                    )
                    
                    result = executor.execute(
                        file_path=test_file,
                        owner_pack="test_pack",
                        input_data={"key": "value"},
                        context=context,
                        timeout_seconds=30.0
                    )
                    
                    self.assertTrue(result.success)
                    self.assertEqual(result.execution_mode, "container")
                finally:
                    os.unlink(test_file)


if __name__ == "__main__":
    unittest.main()
```

---

これで Step 1 と Step 2 の主要な実装が完了しました。

次に進む前に、ここまでの変更内容を確認してください：

1. **`flows/00_startup.flow.yaml`**: `egress_proxy_start` ステップを追加
2. **`core_runtime/kernel.py`**: `load_flow` メソッドを修正（new flow 優先、旧 flow は fallback）
3. **`core_runtime/python_file_executor.py`**: `_execute_in_container` を実装、`container_stub` を廃止
4. **`tests/test_secure_execution.py`**: 新規テストファイル

確認できましたら、Step 5（vocab/converter 強化）に進みます。

修正します。

---

## 修正1: `core_runtime/python_file_executor.py`

### import文の追加（ファイル先頭に追加）

```python
import json
import uuid
```

### `_execute_in_container` メソッドの修正

```python
def _execute_in_container(
    self,
    file_path: Path,
    owner_pack: Optional[str],
    input_data: Any,
    context: ExecutionContext,
    timeout_seconds: float
) -> ExecutionResult:
    """
    Dockerコンテナ内でPythonファイルを実行
    
    docker run --rm で1回実行する方式（シンプル・安全）
    """
    import subprocess
    import tempfile
    
    result = ExecutionResult(success=False, execution_mode="container")
    
    # 一意なコンテナ名を生成（UUID使用で衝突回避）
    unique_id = uuid.uuid4().hex[:12]
    container_name = f"rumi-pfc-{owner_pack or 'unknown'}-{unique_id}"
    
    # 入力データとコンテキストをJSON化
    exec_context = {
        "flow_id": context.flow_id,
        "step_id": context.step_id,
        "phase": context.phase,
        "ts": context.ts,
        "owner_pack": owner_pack,
        "inputs": input_data,
    }
    
    # 一時ファイルのパスを事前に初期化
    input_file = None
    script_file = None
    
    try:
        # 一時ファイルに入力データを書き込み
        with tempfile.NamedTemporaryFile(mode='w', suffix='.json', delete=False) as f:
            json.dump({"input_data": input_data, "context": exec_context}, f, ensure_ascii=False, default=str)
            input_file = f.name
        
        # 実行スクリプトを生成
        executor_script = self._generate_executor_script(file_path.name)
        
        with tempfile.NamedTemporaryFile(mode='w', suffix='.py', delete=False) as f:
            f.write(executor_script)
            script_file = f.name
        
        # Docker実行コマンドを構築
        docker_cmd = [
            "docker", "run",
            "--rm",
            "--name", container_name,
            "--network=none",  # ネットワーク隔離
            "--cap-drop=ALL",  # 全権限を削除
            "--security-opt=no-new-privileges:true",
            "--read-only",  # 読み取り専用ファイルシステム
            "--tmpfs=/tmp:size=64m,noexec,nosuid",  # 一時領域
            "--memory=256m",
            "--memory-swap=256m",
            "--cpus=0.5",
            "--pids-limit=100",
            "--user=65534:65534",  # nobody ユーザー
            "-v", f"{file_path.parent.resolve()}:/workspace:ro",  # ソースディレクトリ（読み取り専用）
            "-v", f"{input_file}:/input.json:ro",  # 入力ファイル
            "-v", f"{script_file}:/executor.py:ro",  # 実行スクリプト
            "-w", "/workspace",
            "--label", "rumi.managed=true",
            "--label", f"rumi.pack_id={owner_pack or 'unknown'}",
            "--label", "rumi.type=python_file_call",
            "python:3.11-slim",
            "python", "/executor.py", file_path.name
        ]
        
        # Docker実行
        try:
            proc_result = subprocess.run(
                docker_cmd,
                capture_output=True,
                text=True,
                timeout=timeout_seconds
            )
            
            if proc_result.returncode == 0:
                # 出力をパース
                output_text = proc_result.stdout.strip()
                if output_text:
                    try:
                        result.output = json.loads(output_text)
                    except json.JSONDecodeError:
                        result.output = output_text
                else:
                    result.output = None
                
                result.success = True
            else:
                result.error = proc_result.stderr or f"Container exited with code {proc_result.returncode}"
                result.error_type = "container_execution_error"
        
        except subprocess.TimeoutExpired:
            # タイムアウト時はコンテナを強制停止
            subprocess.run(["docker", "kill", container_name], capture_output=True)
            result.error = f"Execution timed out after {timeout_seconds}s"
            result.error_type = "timeout"
        
    except Exception as e:
        result.error = str(e)
        result.error_type = type(e).__name__
    
    finally:
        # 一時ファイルを削除（存在する場合のみ）
        if input_file is not None:
            try:
                os.unlink(input_file)
            except Exception:
                pass
        if script_file is not None:
            try:
                os.unlink(script_file)
            except Exception:
                pass
    
    return result
```

---

## 修正2: `tests/test_secure_execution.py`

### `TestDockerExecution` クラスの修正

```python
class TestDockerExecution(unittest.TestCase):
    """Docker実行のテスト（Dockerが利用可能な環境でのみ実行）"""
    
    docker_available = False
    
    @classmethod
    def setUpClass(cls):
        """Dockerが利用可能か確認"""
        import subprocess
        try:
            result = subprocess.run(["docker", "info"], capture_output=True, timeout=10)
            cls.docker_available = result.returncode == 0
        except Exception:
            cls.docker_available = False
    
    def setUp(self):
        self.original_security_mode = os.environ.get("RUMI_SECURITY_MODE")
        os.environ["RUMI_SECURITY_MODE"] = "strict"
        reset_python_file_executor()
    
    def tearDown(self):
        if self.original_security_mode:
            os.environ["RUMI_SECURITY_MODE"] = self.original_security_mode
        elif "RUMI_SECURITY_MODE" in os.environ:
            del os.environ["RUMI_SECURITY_MODE"]
        reset_python_file_executor()
    
    def test_docker_execution_succeeds(self):
        """Docker実行が成功すること"""
        if not self.docker_available:
            self.skipTest("Docker not available")
        
        executor = PythonFileExecutor()
        
        # 承認チェックをパス
        with patch.object(executor._approval_checker, 'is_approved', return_value=(True, None)):
            with patch.object(executor._approval_checker, 'verify_hash', return_value=(True, None)):
                with tempfile.NamedTemporaryFile(mode='w', suffix='.py', delete=False) as f:
                    f.write("def run(input_data, context=None): return {'result': 'docker_test'}")
                    test_file = f.name
                
                try:
                    executor._path_validator.add_allowed_root(str(Path(test_file).parent))
                    
                    context = ExecutionContext(
                        flow_id="test_flow",
                        step_id="test_step",
                        phase="test",
                        ts="2024-01-01T00:00:00Z",
                        owner_pack="test_pack",
                        inputs={},
                    )
                    
                    result = executor.execute(
                        file_path=test_file,
                        owner_pack="test_pack",
                        input_data={"key": "value"},
                        context=context,
                        timeout_seconds=30.0
                    )
                    
                    self.assertTrue(result.success)
                    self.assertEqual(result.execution_mode, "container")
                finally:
                    os.unlink(test_file)
```

---

修正内容のまとめ：

1. **一時ファイル管理**: `input_file` と `script_file` を `None` で事前初期化し、`finally` で存在チェック
2. **import json**: 明示的に追加（`import uuid` も追加）
3. **テストデコレータ**: `@unittest.skipUnless` を削除し、テストメソッド内で `self.skipTest()` を使用
4. **コンテナ名の一意性**: `uuid.uuid4().hex[:12]` を使用して衝突を回避

## Step 5: vocab/converter 強化

### 5-1. converter 実行時の監査ログ

**`core_runtime/vocab_registry.py` の修正：**

### 修正1: `convert` メソッドに監査ログを追加

`VocabRegistry` クラスの `convert` メソッドを以下で置き換えてください：

```python
def convert(
    self,
    from_term: str,
    to_term: str,
    data: Any,
    context: Dict[str, Any] = None,
    log_success: bool = False
) -> Tuple[Any, bool]:
    """
    データを変換
    
    Args:
        from_term: 変換元の語
        to_term: 変換先の語
        data: 変換するデータ
        context: 変換コンテキスト
        log_success: 成功時も監査ログに記録するか（デフォルトはFalse、ログ過多防止）
    
    Returns:
        (変換後のデータ, 成功したか)
    """
    from_lower = from_term.strip().lower()
    to_lower = to_term.strip().lower()
    
    with self._lock:
        key = (from_lower, to_lower)
        converter_info = self._converters.get(key)
    
    if converter_info is None:
        return data, False
    
    convert_fn = self._get_converter_function(converter_info)
    if convert_fn is None:
        # 変換関数のロード失敗を監査ログに記録
        self._log_conversion(
            from_term=from_term,
            to_term=to_term,
            success=False,
            error="Failed to load converter function",
            converter_info=converter_info
        )
        return data, False
    
    try:
        if context is not None:
            result = convert_fn(data, context)
        else:
            result = convert_fn(data)
        
        # 成功時のログ（オプション）
        if log_success:
            self._log_conversion(
                from_term=from_term,
                to_term=to_term,
                success=True,
                converter_info=converter_info
            )
        
        return result, True
    except Exception as e:
        # 失敗時は必ず監査ログに記録
        self._log_conversion(
            from_term=from_term,
            to_term=to_term,
            success=False,
            error=str(e),
            error_type=type(e).__name__,
            converter_info=converter_info
        )
        print(f"[VocabRegistry] Converter error ({from_term} -> {to_term}): {e}")
        return data, False

def _log_conversion(
    self,
    from_term: str,
    to_term: str,
    success: bool,
    error: str = None,
    error_type: str = None,
    converter_info: ConverterInfo = None
) -> None:
    """変換の監査ログを記録"""
    try:
        from .audit_logger import get_audit_logger
        audit = get_audit_logger()
        
        details = {
            "from_term": from_term,
            "to_term": to_term,
        }
        
        if converter_info:
            details["converter_file"] = str(converter_info.file_path)
            details["source_pack"] = converter_info.source_pack
        
        if error:
            details["error"] = error
        if error_type:
            details["error_type"] = error_type
        
        audit.log_system_event(
            event_type="vocab_conversion",
            success=success,
            details=details
        )
    except Exception:
        pass  # 監査ログのエラーで処理を止めない
```

### 5-2. 登録された語彙/converter の可視化

### 修正2: provenance 情報を強化した一覧取得メソッドを追加

`VocabRegistry` クラスに以下のメソッドを追加してください（既存の `list_groups` と `list_converters` の後に追加）：

```python
def get_registration_summary(self) -> Dict[str, Any]:
    """
    登録状況のサマリーを取得（どのpackがどの語彙を登録したか）
    
    Returns:
        {
            "groups": {pack_id: [groups...]},
            "converters": {pack_id: [converters...]},
            "loaded_packs": [pack_ids...],
            "totals": {"groups": n, "converters": m}
        }
    """
    with self._lock:
        # Pack別にグループを集計
        groups_by_pack: Dict[str, List[Dict[str, Any]]] = {}
        for gid, group in self._groups.items():
            pack_id = group.source_pack or "_unknown"
            if pack_id not in groups_by_pack:
                groups_by_pack[pack_id] = []
            groups_by_pack[pack_id].append({
                "id": gid,
                "preferred": group.preferred,
                "members": sorted(group.members),
            })
        
        # Pack別にconverterを集計
        converters_by_pack: Dict[str, List[Dict[str, Any]]] = {}
        for converter in self._converters.values():
            pack_id = converter.source_pack or "_unknown"
            if pack_id not in converters_by_pack:
                converters_by_pack[pack_id] = []
            converters_by_pack[pack_id].append({
                "from": converter.from_term,
                "to": converter.to_term,
                "file": str(converter.file_path),
            })
        
        return {
            "groups_by_pack": groups_by_pack,
            "converters_by_pack": converters_by_pack,
            "loaded_packs": sorted(self._loaded_packs),
            "totals": {
                "groups": len(self._groups),
                "converters": len(self._converters),
                "packs": len(self._loaded_packs),
            }
        }
```

### 修正3: Kernel ハンドラの追加

**`core_runtime/kernel.py` の修正：**

`_init_kernel_handlers` メソッド内のハンドラ辞書に以下を追加してください：

```python
"kernel:vocab.list_groups": self._h_vocab_list_groups,
"kernel:vocab.list_converters": self._h_vocab_list_converters,
"kernel:vocab.summary": self._h_vocab_summary,
"kernel:vocab.convert": self._h_vocab_convert,
```

同じファイルに以下のハンドラメソッドを追加してください（他の `_h_` メソッドの近くに）：

```python
def _h_vocab_list_groups(self, args: Dict[str, Any], ctx: Dict[str, Any]) -> Any:
    """登録された同義語グループを一覧"""
    try:
        from .vocab_registry import get_vocab_registry
        vr = get_vocab_registry()
        groups = vr.list_groups()
        return {
            "_kernel_step_status": "success",
            "_kernel_step_meta": {"count": len(groups)},
            "groups": groups
        }
    except Exception as e:
        return {"_kernel_step_status": "failed", "_kernel_step_meta": {"error": str(e)}}

def _h_vocab_list_converters(self, args: Dict[str, Any], ctx: Dict[str, Any]) -> Any:
    """登録されたconverterを一覧"""
    try:
        from .vocab_registry import get_vocab_registry
        vr = get_vocab_registry()
        converters = vr.list_converters()
        return {
            "_kernel_step_status": "success",
            "_kernel_step_meta": {"count": len(converters)},
            "converters": converters
        }
    except Exception as e:
        return {"_kernel_step_status": "failed", "_kernel_step_meta": {"error": str(e)}}

def _h_vocab_summary(self, args: Dict[str, Any], ctx: Dict[str, Any]) -> Any:
    """vocab/converterの登録状況サマリーを取得"""
    try:
        from .vocab_registry import get_vocab_registry
        vr = get_vocab_registry()
        summary = vr.get_registration_summary()
        return {
            "_kernel_step_status": "success",
            "_kernel_step_meta": summary.get("totals", {}),
            "summary": summary
        }
    except Exception as e:
        return {"_kernel_step_status": "failed", "_kernel_step_meta": {"error": str(e)}}

def _h_vocab_convert(self, args: Dict[str, Any], ctx: Dict[str, Any]) -> Any:
    """データを変換"""
    from_term = args.get("from_term")
    to_term = args.get("to_term")
    data = args.get("data")
    log_success = args.get("log_success", False)
    
    if not from_term or not to_term:
        return {"_kernel_step_status": "failed", "_kernel_step_meta": {"error": "Missing from_term or to_term"}}
    
    try:
        from .vocab_registry import get_vocab_registry
        vr = get_vocab_registry()
        result, success = vr.convert(from_term, to_term, data, log_success=log_success)
        return {
            "_kernel_step_status": "success" if success else "failed",
            "_kernel_step_meta": {"converted": success, "from": from_term, "to": to_term},
            "result": result
        }
    except Exception as e:
        return {"_kernel_step_status": "failed", "_kernel_step_meta": {"error": str(e)}}
```

---

## Step 3: 共有辞書の枠実装

### 3-1. ディレクトリ構造の作成

**新規ファイル: `core_runtime/shared_dict/__init__.py`**

```python
"""
shared_dict - 共有辞書システム

任意の namespace/token を書き換えできる共有辞書の枠を提供する。
公式は namespace の意味を解釈しない（ecosystem が自由に決める）。

Usage:
    from core_runtime.shared_dict import get_shared_dict_resolver
    
    resolver = get_shared_dict_resolver()
    
    # 解決
    resolved = resolver.resolve("flow_id", "old_name")
    
    # 提案
    result = resolver.propose("flow_id", "old_name", "new_name", provenance={...})
"""

from .resolver import (
    SharedDictResolver,
    get_shared_dict_resolver,
    reset_shared_dict_resolver,
)
from .journal import (
    SharedDictJournal,
    ProposalResult,
    get_shared_dict_journal,
    reset_shared_dict_journal,
)
from .snapshot import (
    SharedDictSnapshot,
    get_shared_dict_snapshot,
    reset_shared_dict_snapshot,
)

__all__ = [
    "SharedDictResolver",
    "get_shared_dict_resolver",
    "reset_shared_dict_resolver",
    "SharedDictJournal",
    "ProposalResult",
    "get_shared_dict_journal",
    "reset_shared_dict_journal",
    "SharedDictSnapshot",
    "get_shared_dict_snapshot",
    "reset_shared_dict_snapshot",
]
```

### 3-2. snapshot.py の実装

**新規ファイル: `core_runtime/shared_dict/snapshot.py`**

```python
"""
snapshot.py - 共有辞書のスナップショット管理

snapshot.json の読み書きを行う。
"""

from __future__ import annotations

import json
import threading
from dataclasses import dataclass, field
from datetime import datetime, timezone
from pathlib import Path
from typing import Any, Dict, List, Optional


@dataclass
class RuleEntry:
    """辞書ルールエントリ"""
    token: str
    value: str
    conditions: Dict[str, Any] = field(default_factory=dict)
    provenance: Dict[str, Any] = field(default_factory=dict)
    
    def to_dict(self) -> Dict[str, Any]:
        return {
            "token": self.token,
            "value": self.value,
            "conditions": self.conditions,
            "provenance": self.provenance,
        }
    
    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> 'RuleEntry':
        return cls(
            token=data.get("token", ""),
            value=data.get("value", ""),
            conditions=data.get("conditions", {}),
            provenance=data.get("provenance", {}),
        )


class SharedDictSnapshot:
    """
    共有辞書スナップショット管理
    
    snapshot.json の読み書きを行う。
    """
    
    DEFAULT_PATH = "user_data/settings/shared_dict/snapshot.json"
    
    def __init__(self, snapshot_path: str = None):
        self._path = Path(snapshot_path) if snapshot_path else Path(self.DEFAULT_PATH)
        self._lock = threading.RLock()
        self._data: Dict[str, Any] = None
        self._load()
    
    def _now_ts(self) -> str:
        return datetime.now(timezone.utc).isoformat().replace("+00:00", "Z")
    
    def _load(self) -> None:
        """スナップショットを読み込む"""
        with self._lock:
            if self._path.exists():
                try:
                    with open(self._path, 'r', encoding='utf-8') as f:
                        self._data = json.load(f)
                except (json.JSONDecodeError, IOError) as e:
                    print(f"[SharedDictSnapshot] Load error: {e}")
                    self._data = self._create_empty()
            else:
                self._data = self._create_empty()
    
    def _create_empty(self) -> Dict[str, Any]:
        """空のスナップショットを作成"""
        return {
            "version": "1.0",
            "created_at": self._now_ts(),
            "updated_at": self._now_ts(),
            "namespaces": {}
        }
    
    def _save(self) -> None:
        """スナップショットを保存"""
        with self._lock:
            self._data["updated_at"] = self._now_ts()
            
            # ディレクトリを作成
            self._path.parent.mkdir(parents=True, exist_ok=True)
            
            try:
                with open(self._path, 'w', encoding='utf-8') as f:
                    json.dump(self._data, f, ensure_ascii=False, indent=2)
            except IOError as e:
                print(f"[SharedDictSnapshot] Save error: {e}")
    
    def get_namespaces(self) -> List[str]:
        """全namespaceを取得"""
        with self._lock:
            return list(self._data.get("namespaces", {}).keys())
    
    def get_rules(self, namespace: str) -> List[RuleEntry]:
        """指定namespaceのルールを取得"""
        with self._lock:
            ns_data = self._data.get("namespaces", {}).get(namespace, {})
            rules_raw = ns_data.get("rules", [])
            return [RuleEntry.from_dict(r) for r in rules_raw]
    
    def get_rule(self, namespace: str, token: str) -> Optional[RuleEntry]:
        """指定namespace/tokenのルールを取得"""
        rules = self.get_rules(namespace)
        for rule in rules:
            if rule.token == token:
                return rule
        return None
    
    def add_rule(
        self,
        namespace: str,
        token: str,
        value: str,
        conditions: Dict[str, Any] = None,
        provenance: Dict[str, Any] = None
    ) -> bool:
        """
        ルールを追加
        
        既に同じtoken/valueが存在する場合は何もしない。
        同じtokenで異なるvalueが存在する場合はFalseを返す（衝突）。
        """
        with self._lock:
            if "namespaces" not in self._data:
                self._data["namespaces"] = {}
            
            if namespace not in self._data["namespaces"]:
                self._data["namespaces"][namespace] = {"rules": []}
            
            rules = self._data["namespaces"][namespace]["rules"]
            
            # 既存ルールをチェック
            for rule in rules:
                if rule.get("token") == token:
                    if rule.get("value") == value:
                        # 同じルールが既に存在
                        return True
                    else:
                        # 衝突
                        return False
            
            # 新しいルールを追加
            new_rule = {
                "token": token,
                "value": value,
                "conditions": conditions or {},
                "provenance": provenance or {},
            }
            rules.append(new_rule)
            self._save()
            return True
    
    def remove_rule(self, namespace: str, token: str) -> bool:
        """ルールを削除"""
        with self._lock:
            if namespace not in self._data.get("namespaces", {}):
                return False
            
            rules = self._data["namespaces"][namespace]["rules"]
            original_len = len(rules)
            
            self._data["namespaces"][namespace]["rules"] = [
                r for r in rules if r.get("token") != token
            ]
            
            if len(self._data["namespaces"][namespace]["rules"]) < original_len:
                self._save()
                return True
            return False
    
    def clear_namespace(self, namespace: str) -> bool:
        """namespaceをクリア"""
        with self._lock:
            if namespace in self._data.get("namespaces", {}):
                del self._data["namespaces"][namespace]
                self._save()
                return True
            return False
    
    def get_all_data(self) -> Dict[str, Any]:
        """全データを取得"""
        with self._lock:
            return dict(self._data)
    
    def reload(self) -> None:
        """スナップショットを再読み込み"""
        self._load()


# グローバルインスタンス
_global_snapshot: Optional[SharedDictSnapshot] = None
_snapshot_lock = threading.Lock()


def get_shared_dict_snapshot() -> SharedDictSnapshot:
    """グローバルなSharedDictSnapshotを取得"""
    global _global_snapshot
    if _global_snapshot is None:
        with _snapshot_lock:
            if _global_snapshot is None:
                _global_snapshot = SharedDictSnapshot()
    return _global_snapshot


def reset_shared_dict_snapshot(snapshot_path: str = None) -> SharedDictSnapshot:
    """SharedDictSnapshotをリセット（テスト用）"""
    global _global_snapshot
    with _snapshot_lock:
        _global_snapshot = SharedDictSnapshot(snapshot_path)
    return _global_snapshot
```

### 3-3. journal.py の実装

**新規ファイル: `core_runtime/shared_dict/journal.py`**

```python
"""
journal.py - 共有辞書のジャーナル管理

全ての操作（提案/採用/拒否/無効化）を追記ログとして記録する。
"""

from __future__ import annotations

import json
import threading
from dataclasses import dataclass, field
from datetime import datetime, timezone
from enum import Enum
from pathlib import Path
from typing import Any, Dict, List, Optional


class ProposalStatus(Enum):
    """提案ステータス"""
    ACCEPTED = "accepted"
    REJECTED = "rejected"
    CONFLICT = "conflict"
    CYCLE_DETECTED = "cycle_detected"


@dataclass
class ProposalResult:
    """提案結果"""
    status: ProposalStatus
    namespace: str
    token: str
    value: str
    reason: Optional[str] = None
    
    @property
    def accepted(self) -> bool:
        return self.status == ProposalStatus.ACCEPTED


@dataclass
class JournalEntry:
    """ジャーナルエントリ"""
    ts: str
    action: str  # propose, remove, clear
    namespace: str
    token: str
    value: str
    result: str  # accepted, rejected, conflict, cycle_detected
    reason: Optional[str] = None
    provenance: Dict[str, Any] = field(default_factory=dict)
    
    def to_dict(self) -> Dict[str, Any]:
        d = {
            "ts": self.ts,
            "action": self.action,
            "namespace": self.namespace,
            "token": self.token,
            "value": self.value,
            "result": self.result,
            "provenance": self.provenance,
        }
        if self.reason:
            d["reason"] = self.reason
        return d
    
    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> 'JournalEntry':
        return cls(
            ts=data.get("ts", ""),
            action=data.get("action", ""),
            namespace=data.get("namespace", ""),
            token=data.get("token", ""),
            value=data.get("value", ""),
            result=data.get("result", ""),
            reason=data.get("reason"),
            provenance=data.get("provenance", {}),
        )


class SharedDictJournal:
    """
    共有辞書ジャーナル管理
    
    全ての操作を journal.jsonl に追記する。
    """
    
    DEFAULT_PATH = "user_data/settings/shared_dict/journal.jsonl"
    
    def __init__(self, journal_path: str = None, snapshot=None):
        self._path = Path(journal_path) if journal_path else Path(self.DEFAULT_PATH)
        self._lock = threading.RLock()
        self._snapshot = snapshot
    
    def _now_ts(self) -> str:
        return datetime.now(timezone.utc).isoformat().replace("+00:00", "Z")
    
    def _get_snapshot(self):
        """スナップショットを取得（遅延初期化）"""
        if self._snapshot is None:
            from .snapshot import get_shared_dict_snapshot
            self._snapshot = get_shared_dict_snapshot()
        return self._snapshot
    
    def _append_entry(self, entry: JournalEntry) -> None:
        """エントリをジャーナルに追記"""
        self._path.parent.mkdir(parents=True, exist_ok=True)
        
        try:
            with open(self._path, 'a', encoding='utf-8') as f:
                f.write(json.dumps(entry.to_dict(), ensure_ascii=False) + "\n")
        except IOError as e:
            print(f"[SharedDictJournal] Append error: {e}")
        
        # 監査ログにも記録
        self._log_to_audit(entry)
    
    def _log_to_audit(self, entry: JournalEntry) -> None:
        """監査ログに記録"""
        try:
            from ..audit_logger import get_audit_logger
            audit = get_audit_logger()
            audit.log_system_event(
                event_type=f"shared_dict_{entry.action}",
                success=entry.result == "accepted",
                details={
                    "namespace": entry.namespace,
                    "token": entry.token,
                    "value": entry.value,
                    "result": entry.result,
                    "reason": entry.reason,
                    "provenance": entry.provenance,
                }
            )
        except Exception:
            pass
    
    def _check_cycle(self, namespace: str, token: str, value: str, max_hops: int = 10) -> bool:
        """
        循環を検出
        
        token -> value -> ... -> token となるパスがあれば True
        """
        snapshot = self._get_snapshot()
        visited = {token}
        current = value
        
        for _ in range(max_hops):
            if current in visited:
                return True  # 循環検出
            
            visited.add(current)
            rule = snapshot.get_rule(namespace, current)
            if rule is None:
                return False  # 終端に達した
            
            current = rule.value
        
        # ホップ上限に達した（潜在的な循環）
        return True
    
    def propose(
        self,
        namespace: str,
        token: str,
        value: str,
        provenance: Dict[str, Any] = None
    ) -> ProposalResult:
        """
        ルールを提案
        
        衝突チェック、循環チェックを行い、結果を返す。
        """
        with self._lock:
            provenance = provenance or {}
            provenance.setdefault("ts", self._now_ts())
            
            # 循環チェック
            if self._check_cycle(namespace, token, value):
                entry = JournalEntry(
                    ts=self._now_ts(),
                    action="propose",
                    namespace=namespace,
                    token=token,
                    value=value,
                    result="cycle_detected",
                    reason=f"Cycle detected: {token} -> {value} creates a loop",
                    provenance=provenance,
                )
                self._append_entry(entry)
                
                return ProposalResult(
                    status=ProposalStatus.CYCLE_DETECTED,
                    namespace=namespace,
                    token=token,
                    value=value,
                    reason=entry.reason,
                )
            
            # スナップショットに追加を試みる
            snapshot = self._get_snapshot()
            success = snapshot.add_rule(
                namespace=namespace,
                token=token,
                value=value,
                conditions={},
                provenance=provenance,
            )
            
            if success:
                entry = JournalEntry(
                    ts=self._now_ts(),
                    action="propose",
                    namespace=namespace,
                    token=token,
                    value=value,
                    result="accepted",
                    provenance=provenance,
                )
                self._append_entry(entry)
                
                return ProposalResult(
                    status=ProposalStatus.ACCEPTED,
                    namespace=namespace,
                    token=token,
                    value=value,
                )
            else:
                # 衝突
                existing = snapshot.get_rule(namespace, token)
                entry = JournalEntry(
                    ts=self._now_ts(),
                    action="propose",
                    namespace=namespace,
                    token=token,
                    value=value,
                    result="conflict",
                    reason=f"Conflict: token '{token}' already maps to '{existing.value if existing else '?'}'",
                    provenance=provenance,
                )
                self._append_entry(entry)
                
                return ProposalResult(
                    status=ProposalStatus.CONFLICT,
                    namespace=namespace,
                    token=token,
                    value=value,
                    reason=entry.reason,
                )
    
    def remove(
        self,
        namespace: str,
        token: str,
        provenance: Dict[str, Any] = None
    ) -> bool:
        """ルールを削除"""
        with self._lock:
            provenance = provenance or {}
            provenance.setdefault("ts", self._now_ts())
            
            snapshot = self._get_snapshot()
            existing = snapshot.get_rule(namespace, token)
            
            if existing is None:
                return False
            
            success = snapshot.remove_rule(namespace, token)
            
            entry = JournalEntry(
                ts=self._now_ts(),
                action="remove",
                namespace=namespace,
                token=token,
                value=existing.value,
                result="accepted" if success else "rejected",
                provenance=provenance,
            )
            self._append_entry(entry)
            
            return success
    
    def get_history(
        self,
        namespace: str = None,
        token: str = None,
        limit: int = 100
    ) -> List[JournalEntry]:
        """履歴を取得"""
        entries = []
        
        if not self._path.exists():
            return entries
        
        try:
            with open(self._path, 'r', encoding='utf-8') as f:
                for line in f:
                    line = line.strip()
                    if not line:
                        continue
                    
                    try:
                        data = json.loads(line)
                        entry = JournalEntry.from_dict(data)
                        
                        # フィルタ
                        if namespace and entry.namespace != namespace:
                            continue
                        if token and entry.token != token:
                            continue
                        
                        entries.append(entry)
                    except (json.JSONDecodeError, Exception):
                        continue
        except IOError:
            pass
        
        # 最新のlimit件を返す
        return entries[-limit:] if len(entries) > limit else entries


# グローバルインスタンス
_global_journal: Optional[SharedDictJournal] = None
_journal_lock = threading.Lock()


def get_shared_dict_journal() -> SharedDictJournal:
    """グローバルなSharedDictJournalを取得"""
    global _global_journal
    if _global_journal is None:
        with _journal_lock:
            if _global_journal is None:
                _global_journal = SharedDictJournal()
    return _global_journal


def reset_shared_dict_journal(journal_path: str = None, snapshot=None) -> SharedDictJournal:
    """SharedDictJournalをリセット（テスト用）"""
    global _global_journal
    with _journal_lock:
        _global_journal = SharedDictJournal(journal_path, snapshot)
    return _global_journal
```

### 3-4. resolver.py の実装

**新規ファイル: `core_runtime/shared_dict/resolver.py`**

```python
"""
resolver.py - 共有辞書の解決エンジン

namespace/token から value を解決する。
循環検出、ホップ上限対応。
"""

from __future__ import annotations

import threading
from dataclasses import dataclass
from datetime import datetime, timezone
from typing import Any, Dict, List, Optional, Tuple


@dataclass
class ResolveResult:
    """解決結果"""
    original: str
    resolved: str
    hops: List[str]  # 解決パス
    cycle_detected: bool = False
    max_hops_reached: bool = False


@dataclass
class ExplainResult:
    """解決の説明"""
    original: str
    resolved: str
    hops: List[Dict[str, Any]]  # 各ホップの詳細
    cycle_detected: bool = False
    max_hops_reached: bool = False


class SharedDictResolver:
    """
    共有辞書解決エンジン
    
    namespace/token を解決して value を返す。
    """
    
    DEFAULT_MAX_HOPS = 10
    
    def __init__(self, snapshot=None, max_hops: int = None):
        self._snapshot = snapshot
        self._max_hops = max_hops or self.DEFAULT_MAX_HOPS
        self._lock = threading.RLock()
    
    def _now_ts(self) -> str:
        return datetime.now(timezone.utc).isoformat().replace("+00:00", "Z")
    
    def _get_snapshot(self):
        """スナップショットを取得（遅延初期化）"""
        if self._snapshot is None:
            from .snapshot import get_shared_dict_snapshot
            self._snapshot = get_shared_dict_snapshot()
        return self._snapshot
    
    def resolve(
        self,
        namespace: str,
        token: str,
        context: Dict[str, Any] = None
    ) -> str:
        """
        token を解決して value を返す
        
        見つからなければ token をそのまま返す。
        循環検出時も token をそのまま返す。
        
        Args:
            namespace: 名前空間
            token: 解決するトークン
            context: 解決コンテキスト（将来の条件評価用、現在は未使用）
        
        Returns:
            解決後の値
        """
        result = self.resolve_chain(namespace, token, context)
        return result.resolved
    
    def resolve_chain(
        self,
        namespace: str,
        token: str,
        context: Dict[str, Any] = None
    ) -> ResolveResult:
        """
        チェーン解決（A→B→C）
        
        循環検出・ホップ上限付き。
        
        Returns:
            ResolveResult（解決パス付き）
        """
        with self._lock:
            snapshot = self._get_snapshot()
            
            visited = set()
            hops = [token]
            current = token
            
            for _ in range(self._max_hops):
                if current in visited:
                    # 循環検出
                    return ResolveResult(
                        original=token,
                        resolved=token,  # 元の値を返す
                        hops=hops,
                        cycle_detected=True,
                    )
                
                visited.add(current)
                rule = snapshot.get_rule(namespace, current)
                
                if rule is None:
                    # 終端に達した
                    return ResolveResult(
                        original=token,
                        resolved=current,
                        hops=hops,
                    )
                
                current = rule.value
                hops.append(current)
            
            # ホップ上限に達した
            return ResolveResult(
                original=token,
                resolved=current,
                hops=hops,
                max_hops_reached=True,
            )
    
    def explain(
        self,
        namespace: str,
        token: str,
        context: Dict[str, Any] = None
    ) -> ExplainResult:
        """
        どのルールが適用されたかを説明
        
        Returns:
            ExplainResult（各ホップの詳細付き）
        """
        with self._lock:
            snapshot = self._get_snapshot()
            
            visited = set()
            hops = []
            current = token
            
            for _ in range(self._max_hops):
                if current in visited:
                    # 循環検出
                    return ExplainResult(
                        original=token,
                        resolved=token,
                        hops=hops,
                        cycle_detected=True,
                    )
                
                visited.add(current)
                rule = snapshot.get_rule(namespace, current)
                
                if rule is None:
                    # 終端に達した
                    hops.append({
                        "token": current,
                        "value": None,
                        "rule_found": False,
                    })
                    return ExplainResult(
                        original=token,
                        resolved=current,
                        hops=hops,
                    )
                
                hops.append({
                    "token": current,
                    "value": rule.value,
                    "rule_found": True,
                    "provenance": rule.provenance,
                })
                
                current = rule.value
            
            # ホップ上限に達した
            return ExplainResult(
                original=token,
                resolved=current,
                hops=hops,
                max_hops_reached=True,
            )
    
    def has_rule(self, namespace: str, token: str) -> bool:
        """ルールが存在するかチェック"""
        snapshot = self._get_snapshot()
        return snapshot.get_rule(namespace, token) is not None
    
    def list_namespaces(self) -> List[str]:
        """全namespaceを取得"""
        snapshot = self._get_snapshot()
        return snapshot.get_namespaces()
    
    def list_rules(self, namespace: str) -> List[Dict[str, Any]]:
        """指定namespaceのルールを取得"""
        snapshot = self._get_snapshot()
        rules = snapshot.get_rules(namespace)
        return [r.to_dict() for r in rules]


# グローバルインスタンス
_global_resolver: Optional[SharedDictResolver] = None
_resolver_lock = threading.Lock()


def get_shared_dict_resolver() -> SharedDictResolver:
    """グローバルなSharedDictResolverを取得"""
    global _global_resolver
    if _global_resolver is None:
        with _resolver_lock:
            if _global_resolver is None:
                _global_resolver = SharedDictResolver()
    return _global_resolver


def reset_shared_dict_resolver(snapshot=None, max_hops: int = None) -> SharedDictResolver:
    """SharedDictResolverをリセット（テスト用）"""
    global _global_resolver
    with _resolver_lock:
        _global_resolver = SharedDictResolver(snapshot, max_hops)
    return _global_resolver
```

### 3-5. Kernel ハンドラの追加

**`core_runtime/kernel.py` の修正：**

`_init_kernel_handlers` メソッド内のハンドラ辞書に以下を追加してください：

```python
"kernel:shared_dict.resolve": self._h_shared_dict_resolve,
"kernel:shared_dict.propose": self._h_shared_dict_propose,
"kernel:shared_dict.explain": self._h_shared_dict_explain,
"kernel:shared_dict.list": self._h_shared_dict_list,
"kernel:shared_dict.remove": self._h_shared_dict_remove,
```

同じファイルに以下のハンドラメソッドを追加してください：

```python
def _h_shared_dict_resolve(self, args: Dict[str, Any], ctx: Dict[str, Any]) -> Any:
    """共有辞書でtokenを解決"""
    namespace = args.get("namespace")
    token = args.get("token")
    
    if not namespace or not token:
        return {"_kernel_step_status": "failed", "_kernel_step_meta": {"error": "Missing namespace or token"}}
    
    try:
        from .shared_dict import get_shared_dict_resolver
        resolver = get_shared_dict_resolver()
        result = resolver.resolve_chain(namespace, token, ctx)
        
        return {
            "_kernel_step_status": "success",
            "_kernel_step_meta": {
                "original": result.original,
                "resolved": result.resolved,
                "hop_count": len(result.hops),
                "cycle_detected": result.cycle_detected,
                "max_hops_reached": result.max_hops_reached,
            },
            "resolved": result.resolved,
            "hops": result.hops,
        }
    except Exception as e:
        return {"_kernel_step_status": "failed", "_kernel_step_meta": {"error": str(e)}}

def _h_shared_dict_propose(self, args: Dict[str, Any], ctx: Dict[str, Any]) -> Any:
    """共有辞書にルールを提案"""
    namespace = args.get("namespace")
    token = args.get("token")
    value = args.get("value")
    provenance = args.get("provenance", {})
    
    if not namespace or not token or value is None:
        return {"_kernel_step_status": "failed", "_kernel_step_meta": {"error": "Missing namespace, token, or value"}}
    
    try:
        from .shared_dict import get_shared_dict_journal
        journal = get_shared_dict_journal()
        result = journal.propose(namespace, token, value, provenance)
        
        return {
            "_kernel_step_status": "success" if result.accepted else "failed",
            "_kernel_step_meta": {
                "status": result.status.value,
                "accepted": result.accepted,
                "reason": result.reason,
            },
            "result": {
                "status": result.status.value,
                "namespace": result.namespace,
                "token": result.token,
                "value": result.value,
                "reason": result.reason,
            }
        }
    except Exception as e:
        return {"_kernel_step_status": "failed", "_kernel_step_meta": {"error": str(e)}}

def _h_shared_dict_explain(self, args: Dict[str, Any], ctx: Dict[str, Any]) -> Any:
    """共有辞書の解決を説明"""
    namespace = args.get("namespace")
    token = args.get("token")
    
    if not namespace or not token:
        return {"_kernel_step_status": "failed", "_kernel_step_meta": {"error": "Missing namespace or token"}}
    
    try:
        from .shared_dict import get_shared_dict_resolver
        resolver = get_shared_dict_resolver()
        result = resolver.explain(namespace, token, ctx)
        
        return {
            "_kernel_step_status": "success",
            "_kernel_step_meta": {
                "original": result.original,
                "resolved": result.resolved,
                "hop_count": len(result.hops),
            },
            "explanation": {
                "original": result.original,
                "resolved": result.resolved,
                "hops": result.hops,
                "cycle_detected": result.cycle_detected,
                "max_hops_reached": result.max_hops_reached,
            }
        }
    except Exception as e:
        return {"_kernel_step_status": "failed", "_kernel_step_meta": {"error": str(e)}}

def _h_shared_dict_list(self, args: Dict[str, Any], ctx: Dict[str, Any]) -> Any:
    """共有辞書のnamespace/ルールを一覧"""
    namespace = args.get("namespace")
    
    try:
        from .shared_dict import get_shared_dict_resolver
        resolver = get_shared_dict_resolver()
        
        if namespace:
            rules = resolver.list_rules(namespace)
            return {
                "_kernel_step_status": "success",
                "_kernel_step_meta": {"namespace": namespace, "rule_count": len(rules)},
                "rules": rules,
            }
        else:
            namespaces = resolver.list_namespaces()
            return {
                "_kernel_step_status": "success",
                "_kernel_step_meta": {"namespace_count": len(namespaces)},
                "namespaces": namespaces,
            }
    except Exception as e:
        return {"_kernel_step_status": "failed", "_kernel_step_meta": {"error": str(e)}}

def _h_shared_dict_remove(self, args: Dict[str, Any], ctx: Dict[str, Any]) -> Any:
    """共有辞書からルールを削除"""
    namespace = args.get("namespace")
    token = args.get("token")
    provenance = args.get("provenance", {})
    
    if not namespace or not token:
        return {"_kernel_step_status": "failed", "_kernel_step_meta": {"error": "Missing namespace or token"}}
    
    try:
        from .shared_dict import get_shared_dict_journal
        journal = get_shared_dict_journal()
        success = journal.remove(namespace, token, provenance)
        
        return {
            "_kernel_step_status": "success" if success else "failed",
            "_kernel_step_meta": {"removed": success, "namespace": namespace, "token": token},
        }
    except Exception as e:
        return {"_kernel_step_status": "failed", "_kernel_step_meta": {"error": str(e)}}
```

### 3-6. テストの追加

**新規ファイル: `tests/test_shared_dict.py`**

```python
"""
共有辞書のテスト

循環検出、衝突検出、ホップ上限などをテストする。
"""

import os
import sys
import tempfile
import unittest
from pathlib import Path

sys.path.insert(0, str(Path(__file__).parent.parent))

from core_runtime.shared_dict.snapshot import SharedDictSnapshot, reset_shared_dict_snapshot
from core_runtime.shared_dict.journal import SharedDictJournal, ProposalStatus, reset_shared_dict_journal
from core_runtime.shared_dict.resolver import SharedDictResolver, reset_shared_dict_resolver


class TestSharedDictSnapshot(unittest.TestCase):
    """スナップショットのテスト"""
    
    def setUp(self):
        self.temp_dir = tempfile.mkdtemp()
        self.snapshot_path = os.path.join(self.temp_dir, "snapshot.json")
        self.snapshot = SharedDictSnapshot(self.snapshot_path)
    
    def tearDown(self):
        import shutil
        shutil.rmtree(self.temp_dir, ignore_errors=True)
    
    def test_add_rule_success(self):
        """ルール追加が成功する"""
        result = self.snapshot.add_rule("test_ns", "A", "B")
        self.assertTrue(result)
        
        rule = self.snapshot.get_rule("test_ns", "A")
        self.assertIsNotNone(rule)
        self.assertEqual(rule.token, "A")
        self.assertEqual(rule.value, "B")
    
    def test_add_duplicate_rule_success(self):
        """同じルールの重複追加は成功する（冪等）"""
        self.snapshot.add_rule("test_ns", "A", "B")
        result = self.snapshot.add_rule("test_ns", "A", "B")
        self.assertTrue(result)
    
    def test_add_conflicting_rule_fails(self):
        """同じtokenに異なるvalueを追加すると失敗する"""
        self.snapshot.add_rule("test_ns", "A", "B")
        result = self.snapshot.add_rule("test_ns", "A", "C")
        self.assertFalse(result)
    
    def test_remove_rule(self):
        """ルール削除が成功する"""
        self.snapshot.add_rule("test_ns", "A", "B")
        result = self.snapshot.remove_rule("test_ns", "A")
        self.assertTrue(result)
        
        rule = self.snapshot.get_rule("test_ns", "A")
        self.assertIsNone(rule)


class TestSharedDictJournal(unittest.TestCase):
    """ジャーナルのテスト"""
    
    def setUp(self):
        self.temp_dir = tempfile.mkdtemp()
        self.snapshot_path = os.path.join(self.temp_dir, "snapshot.json")
        self.journal_path = os.path.join(self.temp_dir, "journal.jsonl")
        
        self.snapshot = SharedDictSnapshot(self.snapshot_path)
        self.journal = SharedDictJournal(self.journal_path, self.snapshot)
    
    def tearDown(self):
        import shutil
        shutil.rmtree(self.temp_dir, ignore_errors=True)
    
    def test_propose_success(self):
        """提案が成功する"""
        result = self.journal.propose("test_ns", "A", "B", {"source_pack_id": "test"})
        
        self.assertTrue(result.accepted)
        self.assertEqual(result.status, ProposalStatus.ACCEPTED)
    
    def test_propose_conflict(self):
        """衝突時に拒否される"""
        self.journal.propose("test_ns", "A", "B")
        result = self.journal.propose("test_ns", "A", "C")
        
        self.assertFalse(result.accepted)
        self.assertEqual(result.status, ProposalStatus.CONFLICT)
    
    def test_propose_cycle_detection(self):
        """循環が検出される（A→B, B→A）"""
        self.journal.propose("test_ns", "A", "B")
        result = self.journal.propose("test_ns", "B", "A")
        
        self.assertFalse(result.accepted)
        self.assertEqual(result.status, ProposalStatus.CYCLE_DETECTED)
    
    def test_propose_longer_cycle_detection(self):
        """長い循環が検出される（A→B→C→A）"""
        self.journal.propose("test_ns", "A", "B")
        self.journal.propose("test_ns", "B", "C")
        result = self.journal.propose("test_ns", "C", "A")
        
        self.assertFalse(result.accepted)
        self.assertEqual(result.status, ProposalStatus.CYCLE_DETECTED)
    
    def test_history(self):
        """履歴が記録される"""
        self.journal.propose("test_ns", "A", "B")
        self.journal.propose("test_ns", "C", "D")
        
        history = self.journal.get_history()
        self.assertEqual(len(history), 2)


class TestSharedDictResolver(unittest.TestCase):
    """リゾルバのテスト"""
    
    def setUp(self):
        self.temp_dir = tempfile.mkdtemp()
        self.snapshot_path = os.path.join(self.temp_dir, "snapshot.json")
        
        self.snapshot = SharedDictSnapshot(self.snapshot_path)
        self.resolver = SharedDictResolver(self.snapshot, max_hops=5)
    
    def tearDown(self):
        import shutil
        shutil.rmtree(self.temp_dir, ignore_errors=True)
    
    def test_resolve_not_found(self):
        """ルールがない場合は元の値を返す"""
        result = self.resolver.resolve("test_ns", "unknown")
        self.assertEqual(result, "unknown")
    
    def test_resolve_single_hop(self):
        """単一ホップの解決"""
        self.snapshot.add_rule("test_ns", "A", "B")
        
        result = self.resolver.resolve("test_ns", "A")
        self.assertEqual(result, "B")
    
    def test_resolve_chain(self):
        """チェーン解決（A→B→C）"""
        self.snapshot.add_rule("test_ns", "A", "B")
        self.snapshot.add_rule("test_ns", "B", "C")
        
        result = self.resolver.resolve("test_ns", "A")
        self.assertEqual(result, "C")
    
    def test_resolve_max_hops(self):
        """ホップ上限に達した場合"""
        # 長いチェーンを作成
        for i in range(10):
            self.snapshot.add_rule("test_ns", f"V{i}", f"V{i+1}")
        
        result = self.resolver.resolve_chain("test_ns", "V0")
        self.assertTrue(result.max_hops_reached)
    
    def test_explain(self):
        """解決の説明が取得できる"""
        self.snapshot.add_rule("test_ns", "A", "B", provenance={"source": "test"})
        self.snapshot.add_rule("test_ns", "B", "C", provenance={"source": "test2"})
        
        result = self.resolver.explain("test_ns", "A")
        
        self.assertEqual(result.original, "A")
        self.assertEqual(result.resolved, "C")
        self.assertEqual(len(result.hops), 3)  # A, B, C


class TestCycleDetectionEdgeCases(unittest.TestCase):
    """循環検出のエッジケーステスト"""
    
    def setUp(self):
        self.temp_dir = tempfile.mkdtemp()
        self.snapshot_path = os.path.join(self.temp_dir, "snapshot.json")
        self.journal_path = os.path.join(self.temp_dir, "journal.jsonl")
        
        self.snapshot = SharedDictSnapshot(self.snapshot_path)
        self.journal = SharedDictJournal(self.journal_path, self.snapshot)
    
    def tearDown(self):
        import shutil
        shutil.rmtree(self.temp_dir, ignore_errors=True)
    
    def test_self_reference_cycle(self):
        """自己参照（A→A）が検出される"""
        result = self.journal.propose("test_ns", "A", "A")
        
        self.assertFalse(result.accepted)
        self.assertEqual(result.status, ProposalStatus.CYCLE_DETECTED)
    
    def test_different_namespaces_no_conflict(self):
        """異なるnamespaceでは衝突しない"""
        result1 = self.journal.propose("ns1", "A", "B")
        result2 = self.journal.propose("ns2", "A", "C")
        
        self.assertTrue(result1.accepted)
        self.assertTrue(result2.accepted)


if __name__ == "__main__":
    unittest.main()
```

---

Step 3 まで完了しました。次は Step 4（辞書解決の適用点）に進みます。続けてよろしいでしょうか？


## Step 4: 辞書解決の適用点

### 4-1. `kernel:flow.execute_by_id` への適用

**`core_runtime/kernel.py` の修正：**

既存の `_h_flow_execute_by_id` メソッドを以下で置き換えてください：

```python
def _h_flow_execute_by_id(self, args: Dict[str, Any], ctx: Dict[str, Any]) -> Any:
    """
    flow_idを指定してFlowを実行
    
    Args:
        flow_id: 実行するFlow ID（必須）
        inputs: Flow入力（任意）
        timeout: タイムアウト秒数（任意）
        resolve: 共有辞書で解決するか（任意、デフォルトFalse）
        resolve_namespace: 解決に使用するnamespace（任意、デフォルト"flow_id"）
    """
    flow_id = args.get("flow_id")
    if not flow_id:
        return {"_kernel_step_status": "failed", "_kernel_step_meta": {"error": "missing flow_id"}}
    
    inputs = args.get("inputs", {})
    timeout = args.get("timeout")
    resolve = args.get("resolve", False)
    resolve_namespace = args.get("resolve_namespace", "flow_id")
    
    # 共有辞書での解決（オプトイン）
    original_flow_id = flow_id
    resolved_flow_id = flow_id
    resolution_info = None
    
    if resolve:
        try:
            from .shared_dict import get_shared_dict_resolver
            resolver = get_shared_dict_resolver()
            result = resolver.resolve_chain(resolve_namespace, flow_id, ctx)
            resolved_flow_id = result.resolved
            
            resolution_info = {
                "original": original_flow_id,
                "resolved": resolved_flow_id,
                "hops": result.hops,
                "cycle_detected": result.cycle_detected,
                "max_hops_reached": result.max_hops_reached,
            }
            
            # 解決された場合は監査ログに記録
            if resolved_flow_id != original_flow_id:
                try:
                    from .audit_logger import get_audit_logger
                    audit = get_audit_logger()
                    audit.log_system_event(
                        event_type="flow_id_resolved",
                        success=True,
                        details={
                            "namespace": resolve_namespace,
                            "original": original_flow_id,
                            "resolved": resolved_flow_id,
                            "hops": result.hops,
                        }
                    )
                except Exception:
                    pass
                
                self.diagnostics.record_step(
                    phase="flow",
                    step_id=f"flow.{original_flow_id}.resolved",
                    handler="kernel:flow.execute_by_id",
                    status="success",
                    meta={
                        "original_flow_id": original_flow_id,
                        "resolved_flow_id": resolved_flow_id,
                        "namespace": resolve_namespace,
                    }
                )
        except Exception as e:
            # 解決失敗時は元のflow_idを使用
            self.diagnostics.record_step(
                phase="flow",
                step_id=f"flow.{original_flow_id}.resolve_failed",
                handler="kernel:flow.execute_by_id",
                status="failed",
                error=e,
                meta={"namespace": resolve_namespace}
            )
    
    # Flow実行
    exec_ctx = dict(ctx)
    exec_ctx.update(inputs)
    
    if resolution_info:
        exec_ctx["_flow_resolution"] = resolution_info
    
    result = self.execute_flow_sync(resolved_flow_id, exec_ctx, timeout)
    
    return {
        "_kernel_step_status": "success" if "_error" not in result else "failed",
        "_kernel_step_meta": {
            "flow_id": resolved_flow_id,
            "original_flow_id": original_flow_id if resolve else None,
            "resolved": resolve and (resolved_flow_id != original_flow_id),
        },
        "result": result
    }
```

### 4-2. modifier 適用への適用

**`core_runtime/flow_modifier.py` の修正：**

### 修正1: `FlowModifierDef` に `resolve_target` フィールドを追加

`FlowModifierDef` データクラスを以下で置き換えてください：

```python
@dataclass
class FlowModifierDef:
    """Flow modifier定義"""
    modifier_id: str
    target_flow_id: str
    phase: str
    priority: int
    action: str  # inject_before, inject_after, append, replace, remove
    target_step_id: Optional[str]
    step: Optional[Dict[str, Any]]  # 注入/置換するステップ定義
    requires: ModifierRequires
    source_file: Optional[Path] = None
    resolve_target: bool = False  # target_flow_idを共有辞書で解決するか
    resolve_namespace: str = "flow_id"  # 解決に使用するnamespace
    
    def to_dict(self) -> Dict[str, Any]:
        return {
            "modifier_id": self.modifier_id,
            "target_flow_id": self.target_flow_id,
            "phase": self.phase,
            "priority": self.priority,
            "action": self.action,
            "target_step_id": self.target_step_id,
            "step": self.step,
            "requires": {
                "interfaces": self.requires.interfaces,
                "capabilities": self.requires.capabilities,
            },
            "_source_file": str(self.source_file) if self.source_file else None,
            "resolve_target": self.resolve_target,
            "resolve_namespace": self.resolve_namespace,
        }
```

### 修正2: `FlowModifierLoader.load_modifier_file` メソッドを修正

`load_modifier_file` メソッド内で、modifier 定義を作成する箇所（`modifier_def = FlowModifierDef(...)` の部分）を以下で置き換えてください：

```python
        # resolve_target（任意）
        resolve_target = raw_data.get("resolve_target", False)
        resolve_namespace = raw_data.get("resolve_namespace", "flow_id")
        
        modifier_def = FlowModifierDef(
            modifier_id=modifier_id,
            target_flow_id=target_flow_id,
            phase=phase,
            priority=priority,
            action=action,
            target_step_id=target_step_id,
            step=step,
            requires=requires,
            source_file=file_path,
            resolve_target=resolve_target,
            resolve_namespace=resolve_namespace,
        )
```

### 修正3: `FlowModifierLoader.get_modifiers_for_flow` メソッドを修正

既存の `get_modifiers_for_flow` メソッドを以下で置き換えてください：

```python
def get_modifiers_for_flow(self, flow_id: str, resolve: bool = False) -> List[FlowModifierDef]:
    """
    特定Flowに対するmodifierを取得(ソート済み)
    
    Args:
        flow_id: Flow ID
        resolve: 共有辞書で target_flow_id を解決するか
    
    Returns:
        マッチするmodifierのリスト
    """
    with self._lock:
        modifiers = []
        
        for m in self._loaded_modifiers.values():
            target = m.target_flow_id
            
            # resolve_target が True の場合、共有辞書で解決
            if m.resolve_target or resolve:
                try:
                    from .shared_dict import get_shared_dict_resolver
                    resolver = get_shared_dict_resolver()
                    target = resolver.resolve(m.resolve_namespace, target)
                except Exception:
                    pass  # 解決失敗時は元の値を使用
            
            if target == flow_id:
                modifiers.append(m)
        
        # phase → priority → modifier_id でソート
        return sorted(modifiers, key=lambda m: (m.phase, m.priority, m.modifier_id))
```

### 修正4: `FlowModifierApplier._apply_single_modifier` に解決ログを追加

`_apply_single_modifier` メソッドの先頭（`result = ModifierApplyResult(...)` の直後）に以下を追加してください：

```python
def _apply_single_modifier(
    self,
    steps: List[FlowStep],
    modifier: FlowModifierDef,
    phases: List[str]
) -> ModifierApplyResult:
    """単一のmodifierを適用"""
    result = ModifierApplyResult(
        success=False,
        modifier_id=modifier.modifier_id,
        action=modifier.action,
        target_flow_id=modifier.target_flow_id,
        target_step_id=modifier.target_step_id
    )
    
    # resolve_target が True の場合のログ
    if modifier.resolve_target:
        try:
            from .shared_dict import get_shared_dict_resolver
            resolver = get_shared_dict_resolver()
            resolved = resolver.resolve(modifier.resolve_namespace, modifier.target_flow_id)
            if resolved != modifier.target_flow_id:
                # 解決された場合は監査ログに記録
                try:
                    from .audit_logger import get_audit_logger
                    audit = get_audit_logger()
                    audit.log_system_event(
                        event_type="modifier_target_resolved",
                        success=True,
                        details={
                            "modifier_id": modifier.modifier_id,
                            "original_target": modifier.target_flow_id,
                            "resolved_target": resolved,
                            "namespace": modifier.resolve_namespace,
                        }
                    )
                except Exception:
                    pass
        except Exception:
            pass
    
    # requires チェック（以降は既存のコード）
    satisfied, reason = self.check_requires(modifier.requires)
    # ... 残りは既存のまま
```

**注意**: 上記は `_apply_single_modifier` メソッドの先頭部分のみの修正です。`# requires チェック` 以降は既存のコードをそのまま残してください。

### 4-3. テストの追加

**新規ファイル: `tests/test_flow_resolution.py`**

```python
"""
Flow解決のテスト

共有辞書によるflow_id解決をテストする。
"""

import os
import sys
import tempfile
import unittest
from pathlib import Path
from unittest.mock import patch, MagicMock

sys.path.insert(0, str(Path(__file__).parent.parent))

from core_runtime.shared_dict.snapshot import SharedDictSnapshot
from core_runtime.shared_dict.journal import SharedDictJournal
from core_runtime.shared_dict.resolver import SharedDictResolver


class TestFlowIdResolution(unittest.TestCase):
    """Flow ID解決のテスト"""
    
    def setUp(self):
        self.temp_dir = tempfile.mkdtemp()
        self.snapshot_path = os.path.join(self.temp_dir, "snapshot.json")
        self.journal_path = os.path.join(self.temp_dir, "journal.jsonl")
        
        self.snapshot = SharedDictSnapshot(self.snapshot_path)
        self.journal = SharedDictJournal(self.journal_path, self.snapshot)
        self.resolver = SharedDictResolver(self.snapshot)
    
    def tearDown(self):
        import shutil
        shutil.rmtree(self.temp_dir, ignore_errors=True)
    
    def test_resolve_disabled_by_default(self):
        """デフォルトでは解決されない（オプトイン）"""
        # エイリアスを登録
        self.journal.propose("flow_id", "old_flow", "new_flow")
        
        # resolve=False（デフォルト）では解決されない
        # Kernelの_h_flow_execute_by_idの動作をシミュレート
        flow_id = "old_flow"
        resolve = False
        
        if resolve:
            flow_id = self.resolver.resolve("flow_id", flow_id)
        
        # 解決されていない
        self.assertEqual(flow_id, "old_flow")
    
    def test_resolve_enabled_resolves_alias(self):
        """resolve=Trueでエイリアスが解決される"""
        # エイリアスを登録
        self.journal.propose("flow_id", "old_flow", "new_flow")
        
        # resolve=True では解決される
        flow_id = "old_flow"
        resolve = True
        
        if resolve:
            flow_id = self.resolver.resolve("flow_id", flow_id)
        
        # 解決された
        self.assertEqual(flow_id, "new_flow")
    
    def test_resolve_unknown_returns_original(self):
        """未知のflow_idは元のまま返される"""
        flow_id = "unknown_flow"
        resolved = self.resolver.resolve("flow_id", flow_id)
        
        self.assertEqual(resolved, "unknown_flow")
    
    def test_resolve_chain(self):
        """チェーン解決（A→B→C）"""
        self.journal.propose("flow_id", "flow_v1", "flow_v2")
        self.journal.propose("flow_id", "flow_v2", "flow_v3")
        
        resolved = self.resolver.resolve("flow_id", "flow_v1")
        
        self.assertEqual(resolved, "flow_v3")
    
    def test_custom_namespace(self):
        """カスタムnamespaceを使用できる"""
        # 異なるnamespaceに登録
        self.journal.propose("custom_ns", "old_id", "new_id")
        
        # flow_id namespaceでは解決されない
        resolved1 = self.resolver.resolve("flow_id", "old_id")
        self.assertEqual(resolved1, "old_id")
        
        # custom_ns namespaceでは解決される
        resolved2 = self.resolver.resolve("custom_ns", "old_id")
        self.assertEqual(resolved2, "new_id")


class TestModifierTargetResolution(unittest.TestCase):
    """Modifier target解決のテスト"""
    
    def setUp(self):
        self.temp_dir = tempfile.mkdtemp()
        self.snapshot_path = os.path.join(self.temp_dir, "snapshot.json")
        self.journal_path = os.path.join(self.temp_dir, "journal.jsonl")
        
        self.snapshot = SharedDictSnapshot(self.snapshot_path)
        self.journal = SharedDictJournal(self.journal_path, self.snapshot)
        self.resolver = SharedDictResolver(self.snapshot)
    
    def tearDown(self):
        import shutil
        shutil.rmtree(self.temp_dir, ignore_errors=True)
    
    def test_modifier_resolve_target_false(self):
        """resolve_target=Falseではターゲットが解決されない"""
        self.journal.propose("flow_id", "old_target", "new_target")
        
        # resolve_target=False のmodifier
        target_flow_id = "old_target"
        resolve_target = False
        
        if resolve_target:
            target_flow_id = self.resolver.resolve("flow_id", target_flow_id)
        
        # 解決されない
        self.assertEqual(target_flow_id, "old_target")
    
    def test_modifier_resolve_target_true(self):
        """resolve_target=Trueでターゲットが解決される"""
        self.journal.propose("flow_id", "old_target", "new_target")
        
        # resolve_target=True のmodifier
        target_flow_id = "old_target"
        resolve_target = True
        
        if resolve_target:
            target_flow_id = self.resolver.resolve("flow_id", target_flow_id)
        
        # 解決される
        self.assertEqual(target_flow_id, "new_target")


class TestKernelFlowExecuteByIdIntegration(unittest.TestCase):
    """Kernelのflow.execute_by_id統合テスト"""
    
    def setUp(self):
        self.temp_dir = tempfile.mkdtemp()
        self.snapshot_path = os.path.join(self.temp_dir, "snapshot.json")
        
        self.snapshot = SharedDictSnapshot(self.snapshot_path)
    
    def tearDown(self):
        import shutil
        shutil.rmtree(self.temp_dir, ignore_errors=True)
    
    def test_execute_by_id_without_resolve(self):
        """resolve=Falseで実行"""
        # モックKernelの動作をシミュレート
        args = {
            "flow_id": "test_flow",
            "resolve": False,
        }
        
        flow_id = args.get("flow_id")
        resolve = args.get("resolve", False)
        
        original_flow_id = flow_id
        resolved_flow_id = flow_id
        
        if resolve:
            # 解決処理（スキップされる）
            pass
        
        self.assertEqual(original_flow_id, resolved_flow_id)
    
    def test_execute_by_id_with_resolve(self):
        """resolve=Trueで実行"""
        # エイリアスを登録
        from core_runtime.shared_dict.journal import SharedDictJournal
        journal = SharedDictJournal(
            os.path.join(self.temp_dir, "journal.jsonl"),
            self.snapshot
        )
        journal.propose("flow_id", "alias_flow", "real_flow")
        
        resolver = SharedDictResolver(self.snapshot)
        
        # モックKernelの動作をシミュレート
        args = {
            "flow_id": "alias_flow",
            "resolve": True,
            "resolve_namespace": "flow_id",
        }
        
        flow_id = args.get("flow_id")
        resolve = args.get("resolve", False)
        resolve_namespace = args.get("resolve_namespace", "flow_id")
        
        original_flow_id = flow_id
        resolved_flow_id = flow_id
        
        if resolve:
            result = resolver.resolve_chain(resolve_namespace, flow_id)
            resolved_flow_id = result.resolved
        
        self.assertEqual(original_flow_id, "alias_flow")
        self.assertEqual(resolved_flow_id, "real_flow")


if __name__ == "__main__":
    unittest.main()
```

---

Step 4 が完了しました。次は Step 6（Egress 強化）に進みます。続けてよろしいでしょうか？

## Step 6: Egress 強化

### 6-1. 監査ログの修正

**`core_runtime/egress_proxy.py` の修正：**

### 修正1: `EgressProxyHandler._log_request` メソッドを修正

既存の `_log_request` メソッドを以下で置き換えてください：

```python
def _log_request(
    self,
    request: ProxyRequest,
    domain: str,
    port: int,
    success: bool,
    status_code: int,
    error: str = None,
    allowed: bool = True,
    rejection_reason: str = None
) -> None:
    """リクエストを監査ログに記録"""
    if self.audit_logger:
        try:
            self.audit_logger.log_network_event(
                pack_id=request.owner_pack,
                domain=domain,
                port=port,
                allowed=allowed,
                reason=rejection_reason if not allowed else None,
                request_details={
                    "method": request.method,
                    "url": request.url,
                    "success": success,
                    "status_code": status_code,
                    "error": error,
                }
            )
        except Exception:
            pass
```

### 修正2: `EgressProxyHandler._process_request` メソッドを修正

既存の `_process_request` メソッドを以下で置き換えてください：

```python
def _process_request(self, request: ProxyRequest) -> ProxyResponse:
    """リクエストを処理"""
    try:
        parsed = urlparse(request.url)
        domain = parsed.hostname or ""
        port = parsed.port or (443 if parsed.scheme == "https" else 80)
    except Exception as e:
        response = ProxyResponse(
            success=False,
            error=f"Invalid URL: {e}",
            error_type="invalid_url",
            allowed=False
        )
        self._log_request(
            request, "", 0, False, 0,
            error=str(e), allowed=False, rejection_reason="invalid_url"
        )
        return response
    
    # ネットワーク権限チェック
    if self.network_grant_manager:
        check_result = self.network_grant_manager.check_access(request.owner_pack, domain, port)
        if not check_result.allowed:
            response = ProxyResponse(
                success=False,
                allowed=False,
                rejection_reason=check_result.reason,
                error=f"Network access denied: {check_result.reason}",
                error_type="network_denied"
            )
            # 拒否を監査ログに記録
            self._log_request(
                request, domain, port, False, 0,
                error=response.error, allowed=False, rejection_reason=check_result.reason
            )
            return response
    
    # HTTPリクエストを実行
    try:
        response = self._execute_http_request(request, domain, port)
        # 成功/失敗を監査ログに記録
        self._log_request(
            request, domain, port,
            success=response.success,
            status_code=response.status_code,
            error=response.error if not response.success else None,
            allowed=True
        )
        return response
    except Exception as e:
        error_msg = str(e)
        response = ProxyResponse(
            success=False,
            error=error_msg,
            error_type=type(e).__name__,
            allowed=True  # 許可はされたが実行失敗
        )
        # 実行失敗を監査ログに記録
        self._log_request(
            request, domain, port, False, 0,
            error=error_msg, allowed=True
        )
        return response
```

### 修正3: `EgressProxyHandler._execute_http_request` メソッドを修正

既存の `_execute_http_request` メソッドを以下で置き換えてください：

```python
def _execute_http_request(self, request: ProxyRequest, domain: str, port: int) -> ProxyResponse:
    """HTTPリクエストを実行"""
    try:
        import http.client
        parsed = urlparse(request.url)
        
        if parsed.scheme == "https":
            context = ssl.create_default_context()
            conn = http.client.HTTPSConnection(domain, port, timeout=request.timeout_seconds, context=context)
        else:
            conn = http.client.HTTPConnection(domain, port, timeout=request.timeout_seconds)
        
        try:
            path = parsed.path or "/"
            if parsed.query:
                path = f"{path}?{parsed.query}"
            
            headers = dict(request.headers)
            if "Host" not in headers:
                headers["Host"] = domain
            
            conn.request(request.method, path, body=request.body, headers=headers)
            resp = conn.getresponse()
            
            resp_headers = {}
            for key, value in resp.getheaders():
                resp_headers[key] = value
            
            resp_body = resp.read()
            
            try:
                body_str = resp_body.decode("utf-8")
            except UnicodeDecodeError:
                import base64
                body_str = base64.b64encode(resp_body).decode("ascii")
                resp_headers["X-Proxy-Body-Encoding"] = "base64"
            
            return ProxyResponse(
                success=True,
                status_code=resp.status,
                headers=resp_headers,
                body=body_str,
                allowed=True
            )
        finally:
            conn.close()
    except socket.timeout:
        return ProxyResponse(
            success=False,
            error="Request timed out",
            error_type="timeout",
            allowed=True  # 許可はされたがタイムアウト
        )
    except Exception as e:
        return ProxyResponse(
            success=False,
            error=str(e),
            error_type=type(e).__name__,
            allowed=True  # 許可はされたが実行失敗
        )
```

---

**`core_runtime/network_grant_manager.py` の修正：**

### 修正4: `_log_access_check` メソッドを修正

既存の `_log_access_check` メソッドを以下で置き換えてください：

```python
def _log_access_check(self, result: NetworkCheckResult) -> None:
    """アクセスチェックを監査ログに記録"""
    try:
        from .audit_logger import get_audit_logger
        audit = get_audit_logger()
        
        # 許可/拒否を明確に記録
        audit.log_network_event(
            pack_id=result.pack_id,
            domain=result.domain or "",
            port=result.port or 0,
            allowed=result.allowed,
            reason=result.reason if not result.allowed else None,
            request_details={
                "check_type": "access_check",
                "grant_enabled": result.grant.enabled if result.grant else None,
                "grant_domains": result.grant.allowed_domains if result.grant else None,
                "grant_ports": result.grant.allowed_ports if result.grant else None,
            }
        )
    except Exception:
        pass
```

---

**`core_runtime/audit_logger.py` の修正：**

### 修正5: `log_network_event` メソッドを確認・修正

既存の `log_network_event` メソッドが以下の形式になっていることを確認してください。異なる場合は置き換えてください：

```python
def log_network_event(
    self,
    pack_id: str,
    domain: str,
    port: int,
    allowed: bool,
    reason: str = None,
    request_details: Dict[str, Any] = None
) -> None:
    """ネットワークイベントログを記録"""
    # severity を allowed に基づいて設定
    if allowed:
        severity: AuditSeverity = "info"
    else:
        severity: AuditSeverity = "warning"
    
    entry = AuditEntry(
        ts=self._now_ts(),
        category="network",
        severity=severity,
        action="network_request",
        success=allowed,  # allowed を success として記録
        owner_pack=pack_id,
        rejection_reason=reason if not allowed else None,
        details={
            "domain": domain,
            "port": port,
            "allowed": allowed,  # 明示的に allowed を記録
            **(request_details or {})
        }
    )
    self.log(entry)
```

---

### 6-2. テストの追加

**新規ファイル: `tests/test_egress_audit.py`**

```python
"""
Egress Proxy 監査ログのテスト

deny/allow/失敗の監査ログ記録をテストする。
"""

import os
import sys
import json
import tempfile
import unittest
from pathlib import Path
from unittest.mock import MagicMock, patch
from datetime import datetime

sys.path.insert(0, str(Path(__file__).parent.parent))

from core_runtime.network_grant_manager import (
    NetworkGrantManager,
    NetworkGrant,
    NetworkCheckResult,
    reset_network_grant_manager,
)
from core_runtime.audit_logger import (
    AuditLogger,
    reset_audit_logger,
)


class TestNetworkGrantAuditLogging(unittest.TestCase):
    """ネットワーク権限チェックの監査ログテスト"""
    
    def setUp(self):
        self.temp_dir = tempfile.mkdtemp()
        self.grants_dir = os.path.join(self.temp_dir, "grants")
        self.audit_dir = os.path.join(self.temp_dir, "audit")
        
        os.makedirs(self.grants_dir, exist_ok=True)
        os.makedirs(self.audit_dir, exist_ok=True)
        
        self.grant_manager = NetworkGrantManager(grants_dir=self.grants_dir)
        self.audit_logger = reset_audit_logger(self.audit_dir)
    
    def tearDown(self):
        import shutil
        shutil.rmtree(self.temp_dir, ignore_errors=True)
    
    def _get_audit_entries(self, category: str = "network") -> list:
        """監査ログエントリを取得"""
        self.audit_logger.flush()
        entries = []
        
        for log_file in Path(self.audit_dir).glob(f"{category}_*.jsonl"):
            with open(log_file, 'r') as f:
                for line in f:
                    if line.strip():
                        entries.append(json.loads(line))
        
        return entries
    
    def test_allowed_access_logs_correctly(self):
        """許可されたアクセスが正しくログに記録される"""
        # Grant を作成
        self.grant_manager.grant_network_access(
            pack_id="test_pack",
            allowed_domains=["api.example.com"],
            allowed_ports=[443]
        )
        
        # アクセスチェック
        result = self.grant_manager.check_access("test_pack", "api.example.com", 443)
        
        self.assertTrue(result.allowed)
        
        # 監査ログを確認
        entries = self._get_audit_entries()
        
        # アクセスチェックのエントリを探す
        check_entries = [e for e in entries if e.get("details", {}).get("check_type") == "access_check"]
        self.assertTrue(len(check_entries) > 0)
        
        last_entry = check_entries[-1]
        self.assertTrue(last_entry.get("success"))
        self.assertEqual(last_entry.get("details", {}).get("allowed"), True)
        self.assertEqual(last_entry.get("details", {}).get("domain"), "api.example.com")
        self.assertEqual(last_entry.get("details", {}).get("port"), 443)
    
    def test_denied_access_logs_correctly(self):
        """拒否されたアクセスが正しくログに記録される"""
        # Grant を作成（異なるドメインのみ許可）
        self.grant_manager.grant_network_access(
            pack_id="test_pack",
            allowed_domains=["api.example.com"],
            allowed_ports=[443]
        )
        
        # 許可されていないドメインへのアクセスチェック
        result = self.grant_manager.check_access("test_pack", "evil.example.com", 443)
        
        self.assertFalse(result.allowed)
        
        # 監査ログを確認
        entries = self._get_audit_entries()
        
        # 拒否エントリを探す
        denied_entries = [e for e in entries if not e.get("success") and e.get("details", {}).get("check_type") == "access_check"]
        self.assertTrue(len(denied_entries) > 0)
        
        last_entry = denied_entries[-1]
        self.assertFalse(last_entry.get("success"))
        self.assertEqual(last_entry.get("details", {}).get("allowed"), False)
        self.assertIsNotNone(last_entry.get("rejection_reason"))
    
    def test_no_grant_logs_correctly(self):
        """Grant がない場合の拒否が正しくログに記録される"""
        # Grant なしでアクセスチェック
        result = self.grant_manager.check_access("unknown_pack", "api.example.com", 443)
        
        self.assertFalse(result.allowed)
        
        # 監査ログを確認
        entries = self._get_audit_entries()
        
        denied_entries = [e for e in entries if not e.get("success")]
        self.assertTrue(len(denied_entries) > 0)
        
        last_entry = denied_entries[-1]
        self.assertIn("No network grant", last_entry.get("rejection_reason", ""))
    
    def test_port_denied_logs_correctly(self):
        """ポートが拒否された場合のログ記録"""
        # 443のみ許可
        self.grant_manager.grant_network_access(
            pack_id="test_pack",
            allowed_domains=["api.example.com"],
            allowed_ports=[443]
        )
        
        # 80番ポートへのアクセス（拒否されるはず）
        result = self.grant_manager.check_access("test_pack", "api.example.com", 80)
        
        self.assertFalse(result.allowed)
        
        # 監査ログを確認
        entries = self._get_audit_entries()
        
        denied_entries = [e for e in entries if not e.get("success") and e.get("details", {}).get("port") == 80]
        self.assertTrue(len(denied_entries) > 0)


class TestEgressProxyAuditLogging(unittest.TestCase):
    """Egress Proxy の監査ログテスト"""
    
    def setUp(self):
        self.temp_dir = tempfile.mkdtemp()
        self.audit_dir = os.path.join(self.temp_dir, "audit")
        os.makedirs(self.audit_dir, exist_ok=True)
        
        self.audit_logger = reset_audit_logger(self.audit_dir)
    
    def tearDown(self):
        import shutil
        shutil.rmtree(self.temp_dir, ignore_errors=True)
    
    def _get_audit_entries(self, category: str = "network") -> list:
        """監査ログエントリを取得"""
        self.audit_logger.flush()
        entries = []
        
        for log_file in Path(self.audit_dir).glob(f"{category}_*.jsonl"):
            with open(log_file, 'r') as f:
                for line in f:
                    if line.strip():
                        entries.append(json.loads(line))
        
        return entries
    
    def test_audit_entry_contains_allowed_field(self):
        """監査エントリに allowed フィールドが含まれる"""
        # 直接 log_network_event を呼び出してテスト
        self.audit_logger.log_network_event(
            pack_id="test_pack",
            domain="api.example.com",
            port=443,
            allowed=True,
            request_details={"method": "GET", "url": "https://api.example.com/test"}
        )
        
        entries = self._get_audit_entries()
        self.assertTrue(len(entries) > 0)
        
        last_entry = entries[-1]
        self.assertEqual(last_entry.get("details", {}).get("allowed"), True)
        self.assertTrue(last_entry.get("success"))
    
    def test_denied_request_audit_entry(self):
        """拒否されたリクエストの監査エントリ"""
        self.audit_logger.log_network_event(
            pack_id="test_pack",
            domain="evil.com",
            port=443,
            allowed=False,
            reason="Domain not in allowed list",
            request_details={"method": "GET", "url": "https://evil.com/malware"}
        )
        
        entries = self._get_audit_entries()
        self.assertTrue(len(entries) > 0)
        
        last_entry = entries[-1]
        self.assertEqual(last_entry.get("details", {}).get("allowed"), False)
        self.assertFalse(last_entry.get("success"))
        self.assertEqual(last_entry.get("rejection_reason"), "Domain not in allowed list")
    
    def test_failed_request_audit_entry(self):
        """失敗したリクエスト（許可はされたが実行失敗）の監査エントリ"""
        self.audit_logger.log_network_event(
            pack_id="test_pack",
            domain="api.example.com",
            port=443,
            allowed=True,  # 許可はされた
            request_details={
                "method": "GET",
                "url": "https://api.example.com/test",
                "success": False,  # しかし実行は失敗
                "error": "Connection timeout"
            }
        )
        
        entries = self._get_audit_entries()
        self.assertTrue(len(entries) > 0)
        
        last_entry = entries[-1]
        # allowed=True なので success=True（許可された）
        self.assertTrue(last_entry.get("success"))
        self.assertEqual(last_entry.get("details", {}).get("allowed"), True)
        # しかし実行は失敗
        self.assertEqual(last_entry.get("details", {}).get("success"), False)
        self.assertEqual(last_entry.get("details", {}).get("error"), "Connection timeout")


class TestAuditLogIntegrity(unittest.TestCase):
    """監査ログの整合性テスト"""
    
    def setUp(self):
        self.temp_dir = tempfile.mkdtemp()
        self.audit_dir = os.path.join(self.temp_dir, "audit")
        os.makedirs(self.audit_dir, exist_ok=True)
        
        self.audit_logger = reset_audit_logger(self.audit_dir)
    
    def tearDown(self):
        import shutil
        shutil.rmtree(self.temp_dir, ignore_errors=True)
    
    def test_all_network_events_have_required_fields(self):
        """全てのネットワークイベントに必須フィールドがある"""
        # 様々なイベントを記録
        events = [
            {"pack_id": "pack1", "domain": "example.com", "port": 443, "allowed": True},
            {"pack_id": "pack2", "domain": "evil.com", "port": 80, "allowed": False, "reason": "Blocked"},
            {"pack_id": "pack3", "domain": "api.test.com", "port": 8080, "allowed": True},
        ]
        
        for event in events:
            self.audit_logger.log_network_event(**event)
        
        self.audit_logger.flush()
        
        # 全エントリを確認
        entries = []
        for log_file in Path(self.audit_dir).glob("network_*.jsonl"):
            with open(log_file, 'r') as f:
                for line in f:
                    if line.strip():
                        entries.append(json.loads(line))
        
        for entry in entries:
            # 必須フィールドの確認
            self.assertIn("ts", entry)
            self.assertIn("category", entry)
            self.assertEqual(entry["category"], "network")
            self.assertIn("success", entry)
            self.assertIn("details", entry)
            self.assertIn("domain", entry["details"])
            self.assertIn("port", entry["details"])
            self.assertIn("allowed", entry["details"])


if __name__ == "__main__":
    unittest.main()
```

---

## ドキュメント更新

最後に、ドキュメントを更新します。

**`README.md` の修正（該当セクションに追加/修正）：**

以下のセクションを README.md の適切な位置に追加してください：

```markdown
## ディレクトリ構造（正規）

```
project_root/
├── flows/                          # 公式Flow（正）- OSブート
│   └── 00_startup.flow.yaml
│
├── ecosystem/
│   ├── flows/                      # ecosystem Flow（正）- アプリ/拡張
│   │   ├── *.flow.yaml
│   │   └── modifiers/              # Flow modifier
│   │       └── *.modifier.yaml
│   │
│   └── packs/                      # Pack格納
│       └── {pack_id}/
│           └── backend/
│               ├── ecosystem.json
│               ├── blocks/         # python_file_call ブロック
│               ├── vocab.txt       # 同義語グループ（任意）
│               └── converters/     # 変換器（任意）
│
├── user_data/
│   ├── settings/
│   │   └── shared_dict/            # 共有辞書データ
│   │       ├── snapshot.json
│   │       └── journal.jsonl
│   ├── permissions/
│   │   ├── network/                # ネットワークGrant
│   │   └── .secret_key
│   └── audit/                      # 監査ログ
│
└── flow/                           # [DEPRECATED] 旧Flowディレクトリ
    ├── core/                       # → flows/ へ移行してください
    └── ecosystem/                  # → ecosystem/flows/ へ移行してください
```

**注意**: `flow/` ディレクトリは非推奨です。新規Flowは `flows/` または `ecosystem/flows/` に配置してください。

## セキュリティモード

環境変数 `RUMI_SECURITY_MODE` で設定：

| モード | Docker | 動作 |
|--------|--------|------|
| `strict`（デフォルト） | 必須 | Docker不可なら実行拒否 |
| `permissive` | 不要 | 警告付きでホスト実行を許可（開発用） |

```bash
# 本番環境（推奨）
export RUMI_SECURITY_MODE=strict

# 開発環境
export RUMI_SECURITY_MODE=permissive
```

## 共有辞書（Shared Dict）

任意の namespace/token を書き換えできる仕組みです。公式は namespace の意味を解釈しません。

### 基本操作

```yaml
# ルールを提案
- type: handler
  input:
    handler: "kernel:shared_dict.propose"
    args:
      namespace: "flow_id"
      token: "old_flow_name"
      value: "new_flow_name"
      provenance:
        source_pack_id: "compat_pack"
        note: "Backward compatibility alias"

# 解決
- type: handler
  input:
    handler: "kernel:shared_dict.resolve"
    args:
      namespace: "flow_id"
      token: "old_flow_name"
```

### Flow実行での解決

```yaml
- type: handler
  input:
    handler: "kernel:flow.execute_by_id"
    args:
      flow_id: "old_flow_name"
      resolve: true                    # オプトイン
      resolve_namespace: "flow_id"     # デフォルト
```

### 安全機能

- **循環検出**: A→B→A のような循環は自動的に拒否
- **衝突検出**: 同じ token に異なる value を登録しようとすると拒否
- **ホップ上限**: デフォルト10ホップで解決を打ち切り
- **監査ログ**: 全ての操作を記録

## vocab/converter

Pack追加だけで互換性を増やせる仕組みです。

### vocab.txt

```
# ecosystem/packs/my_pack/backend/vocab.txt
tool, function_calling, tools, tooluse
thinking_budget, reasoning_effort
```

### converters

```python
# ecosystem/packs/my_pack/backend/converters/tool_to_function_calling.py
def convert(data, context=None):
    # tool形式 → function_calling形式に変換
    return transformed_data
```
```

---

これで全ての Step（1, 2, 5, 3, 4, 6）の実装が完了しました。

### 実装サマリー

| Step | 内容 | ファイル |
|------|------|----------|
| 1 | 起動統一（new flow正規化） | `flows/00_startup.flow.yaml`, `kernel.py` |
| 2 | strict隔離（Docker実行） | `python_file_executor.py`, `tests/test_secure_execution.py` |
| 5 | vocab/converter強化 | `vocab_registry.py`, `kernel.py` |
| 3 | 共有辞書枠 | `shared_dict/`（新規）, `tests/test_shared_dict.py` |
| 4 | 辞書適用点 | `kernel.py`, `flow_modifier.py`, `tests/test_flow_resolution.py` |
| 6 | Egress強化 | `egress_proxy.py`, `network_grant_manager.py`, `audit_logger.py`, `tests/test_egress_audit.py` |

### 新規作成ファイル

1. `core_runtime/shared_dict/__init__.py`
2. `core_runtime/shared_dict/snapshot.py`
3. `core_runtime/shared_dict/journal.py`
4. `core_runtime/shared_dict/resolver.py`
5. `tests/test_secure_execution.py`
6. `tests/test_shared_dict.py`
7. `tests/test_flow_resolution.py`
8. `tests/test_egress_audit.py`