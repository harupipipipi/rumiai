"""
Webæ¤œç´¢ãƒ„ãƒ¼ãƒ«
Bingã§æ¤œç´¢ã—ã€ä¸Šä½ã‚µã‚¤ãƒˆã®æƒ…å ±ã‚’ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã—ã¦è¿”ã™
"""

import os
import re
import time
import json
import base64
import threading
from pathlib import Path
from http.server import HTTPServer, BaseHTTPRequestHandler
import urllib.parse as urlparse
from concurrent.futures import ThreadPoolExecutor, as_completed

from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import TimeoutException, WebDriverException
import urllib.parse

# UIè¨­å®š
UI_HTML_FILE = "search_results.html"  # ä½¿ç”¨ã™ã‚‹HTMLãƒ•ã‚¡ã‚¤ãƒ«å

TOOL_NAME = "Webæ¤œç´¢"
TOOL_DESCRIPTION = "Bingã§æ¤œç´¢ã—ã€ä¸Šä½ã‚µã‚¤ãƒˆã®æƒ…å ±ã‚’å–å¾—ã—ã¦ãƒ†ã‚­ã‚¹ãƒˆã¨ã—ã¦è¿”ã—ã¾ã™"
TOOL_ICON = '<svg class="w-4 h-4" fill="currentColor" viewBox="0 0 20 20"><path fill-rule="evenodd" d="M8 4a4 4 0 100 8 4 4 0 000-8zM2 8a6 6 0 1110.89 3.476l4.817 4.817a1 1 0 01-1.414 1.414l-4.816-4.816A6 6 0 012 8z" clip-rule="evenodd"></path></svg>'

# ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°
screenshots_data = {}
screenshots_lock = threading.Lock()
ui_data = {
    'query': '',
    'results': [],
    'screenshots': {},
    'status': 'ready',
    'last_update': 0,
    'progress': {
        'total': 0,
        'completed': 0,
        'current_site': ''
    }
}
ui_data_lock = threading.Lock()
ui_server = None
ui_server_port = None

def get_function_declaration():
    """Gemini Function Callingç”¨ã®é–¢æ•°å®šç¾©ã‚’è¿”ã™"""
    return {
        "name": "web_search",
        "description": TOOL_DESCRIPTION,
        "parameters": {
            "type": "object",
            "required": ["query"],
            "properties": {
                "query": {
                    "type": "string",
                    "description": "æ¤œç´¢ã‚¯ã‚¨ãƒª"
                },
                "max_results": {
                    "type": "integer",
                    "description": "å–å¾—ã™ã‚‹æ¤œç´¢çµæœã®æœ€å¤§æ•°ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 3ï¼‰",
                    "default": 3
                },
                "parallel_workers": {
                    "type": "integer",
                    "description": "ä¸¦åˆ—å‡¦ç†ã®ãƒ¯ãƒ¼ã‚«ãƒ¼æ•°ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 3ï¼‰",
                    "default": 3
                }
            }
        }
    }

def get_settings_schema():
    """è¨­å®šé …ç›®ã®ã‚¹ã‚­ãƒ¼ãƒã‚’è¿”ã™"""
    return {
        "headless": {
            "type": "boolean",
            "label": "ãƒ˜ãƒƒãƒ‰ãƒ¬ã‚¹ãƒ¢ãƒ¼ãƒ‰",
            "description": "ãƒ–ãƒ©ã‚¦ã‚¶ã‚’éè¡¨ç¤ºã§å®Ÿè¡Œï¼ˆé«˜é€ŸåŒ–ï¼‰",
            "default": True
        },
        "timeout": {
            "type": "number",
            "label": "ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆï¼ˆç§’ï¼‰",
            "description": "å„ãƒšãƒ¼ã‚¸ã®èª­ã¿è¾¼ã¿ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ",
            "default": 10,
            "min": 5,
            "max": 60,
            "step": 5
        },
        "scrape_images": {
            "type": "boolean",
            "label": "ç”»åƒURLã‚’åé›†",
            "description": "ãƒšãƒ¼ã‚¸å†…ã®ç”»åƒURLã‚‚å–å¾—ã™ã‚‹",
            "default": True
        },
        "max_text_length": {
            "type": "number",
            "label": "æœ€å¤§ãƒ†ã‚­ã‚¹ãƒˆé•·",
            "description": "å„ãƒšãƒ¼ã‚¸ã‹ã‚‰å–å¾—ã™ã‚‹æœ€å¤§æ–‡å­—æ•°",
            "default": 5000,
            "min": 1000,
            "max": 20000,
            "step": 1000
        },
        "capture_screenshots": {
            "type": "boolean",
            "label": "ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆå–å¾—",
            "description": "å„ãƒšãƒ¼ã‚¸ã®ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆã‚’å–å¾—",
            "default": True
        }
    }

def get_ui_info():
    """UIæƒ…å ±ã‚’è¿”ã™ï¼ˆtool_loaderã‹ã‚‰å‘¼ã°ã‚Œã‚‹ï¼‰"""
    return {
        "has_ui": True,
        "html_file": UI_HTML_FILE,
        "default_port": 6001
    }

class ToolUIHandler(BaseHTTPRequestHandler):
    """ãƒ„ãƒ¼ãƒ«å°‚ç”¨ã®HTTPãƒãƒ³ãƒ‰ãƒ©ãƒ¼"""
    
    def log_message(self, format, *args):
        """ãƒ­ã‚°å‡ºåŠ›ã‚’æŠ‘åˆ¶"""
        pass
    
    def do_GET(self):
        """GETãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’å‡¦ç†"""
        parsed_path = urlparse.urlparse(self.path)
        path = parsed_path.path
        
        # Server-Sent Events ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
        if path == '/events':
            self.send_response(200)
            self.send_header('Content-Type', 'text/event-stream')
            self.send_header('Cache-Control', 'no-cache')
            self.send_header('Access-Control-Allow-Origin', '*')
            self.send_header('Connection', 'keep-alive')
            self.end_headers()
            
            # SSEã§ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ‡ãƒ¼ã‚¿ã‚’é€ä¿¡
            last_update = 0
            try:
                while True:
                    with ui_data_lock:
                        if ui_data['last_update'] > last_update:
                            event_data = json.dumps(ui_data)
                            self.wfile.write(f"data: {event_data}\n\n".encode('utf-8'))
                            self.wfile.flush()
                            last_update = ui_data['last_update']
                    
                    time.sleep(0.5)  # 500msé–“éš”ã§ãƒã‚§ãƒƒã‚¯
            except (BrokenPipeError, ConnectionAbortedError):
                pass  # ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãŒåˆ‡æ–­ã—ãŸ
        
        # ãƒ«ãƒ¼ãƒˆã¾ãŸã¯HTMLãƒ•ã‚¡ã‚¤ãƒ«ã¸ã®ã‚¢ã‚¯ã‚»ã‚¹
        elif path == '/' or path.endswith('.html'):
            # HTMLãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¢ã™
            tool_dir = Path(__file__).parent
            
            # æŒ‡å®šã•ã‚ŒãŸHTMLãƒ•ã‚¡ã‚¤ãƒ«ã¾ãŸã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
            if path == '/':
                html_file = tool_dir / UI_HTML_FILE
            else:
                html_file = tool_dir / path.lstrip('/')
            
            if html_file.exists():
                self.send_response(200)
                self.send_header('Content-Type', 'text/html; charset=utf-8')
                self.send_header('Access-Control-Allow-Origin', '*')
                self.end_headers()
                
                with open(html_file, 'r', encoding='utf-8') as f:
                    html_content = f.read()
                
                # ãƒ„ãƒ¼ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’æ³¨å…¥
                html_content = self.inject_tool_data(html_content)
                self.wfile.write(html_content.encode('utf-8'))
            else:
                self.send_error(404, "HTML file not found")
        
        # API ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
        elif path == '/api/status':
            self.send_response(200)
            self.send_header('Content-Type', 'application/json')
            self.send_header('Access-Control-Allow-Origin', '*')
            self.end_headers()
            
            with ui_data_lock:
                status_data = {
                    "status": "running",
                    "data": ui_data,
                    "screenshots_available": len(screenshots_data)
                }
            self.wfile.write(json.dumps(status_data).encode('utf-8'))
        
        # ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆ
        elif path.startswith('/screenshot/'):
            try:
                index = int(path.split('/')[-1])
                screenshot_key = f"screenshot_{index}"
                
                with screenshots_lock:
                    if screenshot_key in screenshots_data:
                        self.send_response(200)
                        self.send_header('Content-Type', 'image/png')
                        self.send_header('Access-Control-Allow-Origin', '*')
                        self.end_headers()
                        img_data = base64.b64decode(screenshots_data[screenshot_key])
                        self.wfile.write(img_data)
                        return
            except:
                pass
            self.send_error(404, "Screenshot not found")
        
        else:
            self.send_error(404, "Not found")
    
    def inject_tool_data(self, html_content):
        """HTMLã«ãƒ„ãƒ¼ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’æ³¨å…¥"""
        inject_script = f"""
        <script>
            window.TOOL_DATA = {json.dumps(ui_data)};
            window.TOOL_PORT = {ui_server_port};
        </script>
        """
        
        if '</head>' in html_content:
            html_content = html_content.replace('</head>', inject_script + '</head>')
        else:
            html_content = inject_script + html_content
        
        return html_content

def start_ui_server(port=None):
    """UIã‚µãƒ¼ãƒãƒ¼ã‚’èµ·å‹•"""
    global ui_server, ui_server_port
    
    if ui_server:
        return ui_server_port  # æ—¢ã«èµ·å‹•ã—ã¦ã„ã‚‹
    
    # ç©ºããƒãƒ¼ãƒˆã‚’æ¢ã™
    if not port:
        import socket
        with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:
            s.bind(('', 0))
            port = s.getsockname()[1]
    
    try:
        ui_server = HTTPServer(('0.0.0.0', port), ToolUIHandler)
        ui_server_port = port
        
        thread = threading.Thread(
            target=ui_server.serve_forever,
            daemon=True
        )
        thread.start()
        
        print(f"Tool UI server started on port {port}")
        return port
    except Exception as e:
        print(f"Failed to start UI server: {e}")
        return None

def stop_ui_server():
    """UIã‚µãƒ¼ãƒãƒ¼ã‚’åœæ­¢"""
    global ui_server, ui_server_port
    
    if ui_server:
        ui_server.shutdown()
        ui_server = None
        ui_server_port = None

def update_ui_data(key, value):
    """UIãƒ‡ãƒ¼ã‚¿ã‚’ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ›´æ–°"""
    global ui_data
    with ui_data_lock:
        if key == 'add_result':
            ui_data['results'].append(value)
        elif key == 'add_screenshot':
            index, data = value
            ui_data['screenshots'][f"screenshot_{index}"] = True
            screenshots_data[f"screenshot_{index}"] = data
        else:
            ui_data[key] = value
        ui_data['last_update'] = time.time()

def create_driver(headless=True):
    """Seleniumãƒ‰ãƒ©ã‚¤ãƒãƒ¼ã‚’ä½œæˆ"""
    options = Options()
    if headless:
        options.add_argument('--headless')
    options.add_argument('--no-sandbox')
    options.add_argument('--disable-dev-shm-usage')
    options.add_argument('--disable-gpu')
    options.add_argument('--window-size=1920,1080')
    options.add_argument('--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36')
    
    # ãƒ­ã‚°ã‚’æŠ‘åˆ¶
    options.add_experimental_option('excludeSwitches', ['enable-logging'])
    options.add_argument('--log-level=3')
    
    driver = webdriver.Chrome(options=options)
    return driver

def search_bing(driver, query, max_results=5):
    """Bingã§æ¤œç´¢ã—ã¦çµæœã®URLã‚’å–å¾—"""
    search_url = f"https://www.bing.com/search?q={urllib.parse.quote(query)}"
    driver.get(search_url)
    
    # æ¤œç´¢çµæœã‚’å¾…ã¤
    wait = WebDriverWait(driver, 10)
    wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, "#b_results")))
    
    # æ¤œç´¢çµæœã®ãƒªãƒ³ã‚¯ã‚’å–å¾—
    results = []
    result_elements = driver.find_elements(By.CSS_SELECTOR, "#b_results .b_algo h2 a")
    
    for element in result_elements[:max_results]:
        try:
            url = element.get_attribute("href")
            title = element.text
            if url and title:
                results.append({"url": url, "title": title})
        except:
            continue
    
    return results

def scrape_page_with_realtime_update(url, title, index, settings, message_callback):
    """å€‹åˆ¥ã®ãƒšãƒ¼ã‚¸ã‚’ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ï¼ˆãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ›´æ–°ä»˜ãï¼‰"""
    # é€²æ—ã‚’æ›´æ–°
    update_ui_data('progress', {
        'total': settings.get('total_sites', 0),
        'completed': index,
        'current_site': title
    })
    
    message_callback(f"[{index + 1}/{settings.get('total_sites', 0)}] {title[:30]}... ã‚’ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ä¸­")
    
    driver = None
    try:
        driver = create_driver(settings['headless'])
        driver.set_page_load_timeout(settings['timeout'])
        driver.get(url)
        
        # ãƒšãƒ¼ã‚¸ã®èª­ã¿è¾¼ã¿ã‚’å¾…ã¤
        WebDriverWait(driver, settings['timeout']).until(
            EC.presence_of_element_located((By.TAG_NAME, "body"))
        )
        
        # JavaScriptã§å‹•çš„ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãŒèª­ã¿è¾¼ã¾ã‚Œã‚‹ã®ã‚’å°‘ã—å¾…ã¤
        time.sleep(2)
        
        # ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆã‚’å–å¾—ã—ã¦ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ›´æ–°
        screenshot_base64 = None
        if settings.get('capture_screenshots', True):
            try:
                # ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚µã‚¤ã‚ºã‚’è¨­å®š
                driver.execute_script("window.scrollTo(0, 0);")
                
                # ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆã‚’å–å¾—
                screenshot_png = driver.get_screenshot_as_png()
                screenshot_base64 = base64.b64encode(screenshot_png).decode('utf-8')
                
                # ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆã‚’ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ›´æ–°
                update_ui_data('add_screenshot', (index, screenshot_base64))
                message_callback(f"ğŸ“¸ {title[:30]}... ã®ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆã‚’å–å¾—")
                
            except Exception as e:
                print(f"ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆå–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
        
        # ãƒ†ã‚­ã‚¹ãƒˆã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’å–å¾—
        text_content = []
        total_length = 0
        max_text_length = settings['max_text_length']
        
        # ä¸»è¦ãªãƒ†ã‚­ã‚¹ãƒˆè¦ç´ ã‚’å–å¾—
        for tag in ["h1", "h2", "h3", "p", "article", "section", "main", "div"]:
            if total_length >= max_text_length:
                break
                
            elements = driver.find_elements(By.TAG_NAME, tag)
            for element in elements:
                if total_length >= max_text_length:
                    break
                    
                try:
                    text = element.text.strip()
                    if text and len(text) > 20:  # çŸ­ã™ãã‚‹ãƒ†ã‚­ã‚¹ãƒˆã¯é™¤å¤–
                        # é‡è¤‡ã‚’é¿ã‘ã‚‹
                        if text not in text_content:
                            text_content.append(text)
                            total_length += len(text)
                except:
                    continue
        
        # ç”»åƒURLã‚’å–å¾—
        image_urls = []
        if settings['scrape_images']:
            img_elements = driver.find_elements(By.TAG_NAME, "img")
            for img in img_elements[:30]:  # æœ€å¤§30å€‹ã¾ã§
                try:
                    src = img.get_attribute("src")
                    alt = img.get_attribute("alt") or ""
                    
                    if src and src.startswith("http"):
                        # ãƒ‡ãƒ¼ã‚¿URLã‚„å°ã•ã™ãã‚‹ç”»åƒã‚’é™¤å¤–
                        if not src.startswith("data:") and "1x1" not in src and "pixel" not in src.lower():
                            image_urls.append({"url": src, "alt": alt})
                except:
                    continue
        
        # ãƒ†ã‚­ã‚¹ãƒˆã‚’çµåˆï¼ˆæœ€å¤§æ–‡å­—æ•°ã¾ã§ï¼‰
        combined_text = "\n\n".join(text_content)
        if len(combined_text) > max_text_length:
            combined_text = combined_text[:max_text_length] + "..."
        
        result = {
            "index": index,
            "url": url,
            "title": title,
            "text": combined_text,
            "images": image_urls[:20],
            "text_length": len(combined_text),
            "image_count": len(image_urls),
            "screenshot": screenshot_base64,
            "success": True
        }
        
        # çµæœã‚’ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ›´æ–°
        update_ui_data('add_result', result)
        message_callback(f"âœ… {title[:30]}... ã®ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°å®Œäº†")
        
        return result
        
    except TimeoutException:
        result = {
            "index": index,
            "url": url,
            "title": title,
            "text": f"[ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ: ãƒšãƒ¼ã‚¸ã®èª­ã¿è¾¼ã¿ã«æ™‚é–“ãŒã‹ã‹ã‚Šã™ãã¾ã—ãŸ]",
            "images": [],
            "text_length": 0,
            "image_count": 0,
            "screenshot": None,
            "success": False
        }
        
        update_ui_data('add_result', result)
        message_callback(f"â±ï¸ {title[:30]}... ãŒã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ")
        
        return result
        
    except Exception as e:
        result = {
            "index": index,
            "url": url,
            "title": title,
            "text": f"[ã‚¨ãƒ©ãƒ¼: ãƒšãƒ¼ã‚¸ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ - {str(e)}]",
            "images": [],
            "text_length": 0,
            "image_count": 0,
            "screenshot": None,
            "success": False
        }
        
        update_ui_data('add_result', result)
        message_callback(f"âŒ {title[:30]}... ã®ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°å¤±æ•—")
        
        return result
        
    finally:
        if driver:
            try:
                driver.quit()
            except:
                pass

def execute(args: dict, context: dict) -> dict:
    """
    ãƒ„ãƒ¼ãƒ«ã®å®Ÿè¡Œ
    
    Args:
        args: AIã‹ã‚‰æ¸¡ã•ã‚ŒãŸå¼•æ•°
        context: å®Ÿè¡Œã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ
    """
    query = args.get("query", "")
    max_results = args.get("max_results", 3)
    parallel_workers = args.get("parallel_workers", 3)
    
    if not query:
        return {
            "success": False,
            "error": "æ¤œç´¢ã‚¯ã‚¨ãƒªãŒæŒ‡å®šã•ã‚Œã¦ã„ã¾ã›ã‚“"
        }
    
    # è¨­å®šã‚’å–å¾—
    settings = context.get("settings", {})
    settings['headless'] = settings.get("headless", True)
    settings['timeout'] = settings.get("timeout", 10)
    settings['scrape_images'] = settings.get("scrape_images", True)
    settings['max_text_length'] = settings.get("max_text_length", 5000)
    settings['capture_screenshots'] = settings.get("capture_screenshots", True)
    
    # ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
    message_callback = context.get("message_callback", lambda x: None)
    
    # ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°ã‚’ã‚¯ãƒªã‚¢
    global screenshots_data
    with screenshots_lock:
        screenshots_data = {}
    
    # UIãƒ‡ãƒ¼ã‚¿ã‚’åˆæœŸåŒ–
    update_ui_data('query', query)
    update_ui_data('results', [])
    update_ui_data('screenshots', {})
    update_ui_data('status', 'searching')
    update_ui_data('progress', {'total': 0, 'completed': 0, 'current_site': 'æ¤œç´¢ä¸­...'})
    
    # UIã‚µãƒ¼ãƒãƒ¼ã‚’èµ·å‹•
    ui_port = start_ui_server()
    ui_info = {}
    if ui_port:
        message_callback(f"ğŸŒ UIã‚µãƒ¼ãƒãƒ¼èµ·å‹•: http://localhost:{ui_port}/")
        ui_info = {
            "ui_available": True,
            "ui_port": ui_port,
            "ui_url": f"http://localhost:{ui_port}/{UI_HTML_FILE}",
            "html_file": UI_HTML_FILE
        }
    else:
        ui_info = {"ui_available": False}
    
    driver = None
    try:
        message_callback(f"æ¤œç´¢ã‚’é–‹å§‹: {query}")
        
        # Bingæ¤œç´¢ç”¨ã®ãƒ‰ãƒ©ã‚¤ãƒãƒ¼
        driver = create_driver(settings['headless'])
        
        # Bingã§æ¤œç´¢
        message_callback(f"Bingã§ã€Œ{query}ã€ã‚’æ¤œç´¢ä¸­...")
        search_results = search_bing(driver, query, max_results)
        
        if not search_results:
            update_ui_data('status', 'no_results')
            return {
                "success": False,
                "error": "æ¤œç´¢çµæœãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ",
                "ui_info": ui_info
            }
        
        message_callback(f"{len(search_results)}ä»¶ã®æ¤œç´¢çµæœã‚’å–å¾—ã—ã¾ã—ãŸ")
        
        # æ¤œç´¢ç”¨ãƒ‰ãƒ©ã‚¤ãƒãƒ¼ã‚’é–‰ã˜ã‚‹
        driver.quit()
        driver = None
        
        # ä¸¦åˆ—ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°è¨­å®š
        update_ui_data('status', 'scraping')
        settings['total_sites'] = len(search_results)
        
        # ä¸¦åˆ—ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°
        message_callback(f"{parallel_workers}å€‹ã®ãƒ¯ãƒ¼ã‚«ãƒ¼ã§ä¸¦åˆ—ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã‚’é–‹å§‹...")
        
        scraped_results = []
        with ThreadPoolExecutor(max_workers=parallel_workers) as executor:
            # ã‚¿ã‚¹ã‚¯ã‚’æŠ•å…¥
            futures = []
            for i, result in enumerate(search_results):
                future = executor.submit(
                    scrape_page_with_realtime_update,
                    result["url"],
                    result["title"],
                    i,
                    settings,
                    message_callback
                )
                futures.append(future)
            
            # çµæœã‚’åé›†
            for future in as_completed(futures):
                try:
                    result = future.result(timeout=settings['timeout'] * 2)
                    scraped_results.append(result)
                except Exception as e:
                    message_callback(f"ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã‚¨ãƒ©ãƒ¼: {str(e)}")
        
        # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹é †ã«ã‚½ãƒ¼ãƒˆ
        scraped_results.sort(key=lambda x: x['index'])
        
        # å®Œäº†çŠ¶æ…‹ã«æ›´æ–°
        update_ui_data('status', 'completed')
        update_ui_data('progress', {
            'total': len(scraped_results),
            'completed': len(scraped_results),
            'current_site': 'å®Œäº†'
        })
        
        message_callback(f"ã™ã¹ã¦ã®ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ãŒå®Œäº†ã—ã¾ã—ãŸ")
        
        # çµæœã‚’æ•´å½¢
        all_scraped_content = []
        scraped_summary = []
        
        for i, result in enumerate(scraped_results, 1):
            page_content = f"""
================================================================================
ã€æ¤œç´¢çµæœ {i}ã€‘
ã‚¿ã‚¤ãƒˆãƒ«: {result['title']}
URL: {result['url']}
================================================================================

ã€æœ¬æ–‡ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã€‘
{result["text"]}
"""
            
            if result["images"]:
                page_content += f"""

ã€ç”»åƒæƒ…å ±ã€‘ï¼ˆ{len(result['images'])}å€‹ï¼‰
"""
                for idx, img_info in enumerate(result["images"][:10], 1):
                    alt_text = f" - {img_info['alt']}" if img_info.get('alt') else ""
                    page_content += f"{idx}. {img_info['url']}{alt_text}\n"
                
                if len(result["images"]) > 10:
                    page_content += f"... ä»– {len(result['images']) - 10} å€‹ã®ç”»åƒ\n"
            
            all_scraped_content.append(page_content)
            
            scraped_summary.append({
                "title": result["title"],
                "url": result["url"],
                "text_length": result.get("text_length", 0),
                "image_count": result.get("image_count", 0),
                "has_screenshot": result.get("screenshot") is not None
            })
        
        # çµæœã‚’çµåˆ
        combined_content = f"""
================================================================================
Webæ¤œç´¢çµæœãƒ¬ãƒãƒ¼ãƒˆ
================================================================================
æ¤œç´¢ã‚¯ã‚¨ãƒª: {query}
æ¤œç´¢æ—¥æ™‚: {time.strftime("%Y-%m-%d %H:%M:%S")}
å–å¾—ä»¶æ•°: {len(scraped_summary)}ä»¶
æ¤œç´¢ã‚¨ãƒ³ã‚¸ãƒ³: Bing
ä¸¦åˆ—ãƒ¯ãƒ¼ã‚«ãƒ¼æ•°: {parallel_workers}

""" + "\n\n".join(all_scraped_content)
        
        # ã‚µãƒãƒªãƒ¼æƒ…å ±
        combined_content += f"""

================================================================================
ã€æ¤œç´¢çµæœã‚µãƒãƒªãƒ¼ã€‘
================================================================================
"""
        total_text = 0
        total_images = 0
        screenshots_count = sum(1 for s in scraped_summary if s['has_screenshot'])
        
        for i, data in enumerate(scraped_summary, 1):
            screenshot_status = "ğŸ“¸" if data['has_screenshot'] else "âŒ"
            combined_content += f"""
{i}. {data['title']}
   URL: {data['url']}
   ãƒ†ã‚­ã‚¹ãƒˆé‡: {data['text_length']:,}æ–‡å­—
   ç”»åƒæ•°: {data['image_count']}å€‹
   ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆ: {screenshot_status}
"""
            total_text += data['text_length']
            total_images += data['image_count']
        
        combined_content += f"""
--------------------------------------------------------------------------------
åˆè¨ˆãƒ†ã‚­ã‚¹ãƒˆé‡: {total_text:,}æ–‡å­—
åˆè¨ˆç”»åƒæ•°: {total_images}å€‹
ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆ: {screenshots_count}å€‹
================================================================================
"""
        
        # çµæœã®æ¦‚è¦ãƒ†ã‚­ã‚¹ãƒˆï¼ˆçŸ­ã„ã‚µãƒãƒªãƒ¼ï¼‰
        result_summary = f"ã€Œ{query}ã€ã®æ¤œç´¢çµæœã‚’{len(scraped_summary)}ä»¶å–å¾—ã—ã¾ã—ãŸã€‚\n\n"
        for data in scraped_summary:
            result_summary += f"â€¢ {data['title'][:50]}{'...' if len(data['title']) > 50 else ''} ({data['text_length']:,}æ–‡å­—)\n"
        
        result_summary += f"\nåˆè¨ˆ: {total_text:,}æ–‡å­—ã®ãƒ†ã‚­ã‚¹ãƒˆã¨{total_images}å€‹ã®ç”»åƒæƒ…å ±ã‚’å–å¾—"
        
        message_callback(f"æ¤œç´¢çµæœã‚’AIã«é€ä¿¡ã—ã¦ã„ã¾ã™...")
        
        # ãƒ†ã‚­ã‚¹ãƒˆã¨ã—ã¦ç›´æ¥è¿”ã™
        return {
            "success": True,
            "result": combined_content,  # ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã—ãŸã™ã¹ã¦ã®å†…å®¹ã‚’å«ã‚€
            "summary": result_summary,
            "scraped_count": len(scraped_summary),
            "total_text_length": len(combined_content),
            "total_images": total_images,
            "screenshots_count": screenshots_count,
            "query": query,
            "sites": [{"title": s["title"], "url": s["url"]} for s in scraped_summary],
            "ui_info": ui_info  # UIæƒ…å ±ã‚’è¿½åŠ 
        }
        
    except WebDriverException as e:
        error_message = f"""
ãƒ–ãƒ©ã‚¦ã‚¶ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚

ã‚¨ãƒ©ãƒ¼è©³ç´°: {str(e)}

è§£æ±ºæ–¹æ³•:
1. Google ChromeãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„
2. ChromeDriverãŒæœ€æ–°ç‰ˆã‹ç¢ºèªã—ã¦ãã ã•ã„
3. ä»¥ä¸‹ã®ã‚³ãƒãƒ³ãƒ‰ã§ChromeDriverã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«/æ›´æ–°ã§ãã¾ã™:
   pip install --upgrade selenium
   pip install webdriver-manager

ãã‚Œã§ã‚‚è§£æ±ºã—ãªã„å ´åˆã¯ã€æ‰‹å‹•ã§ChromeDriverã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„:
https://chromedriver.chromium.org/
"""
        update_ui_data('status', 'error')
        return {
            "success": False,
            "error": error_message,
            "ui_info": ui_info
        }
    except Exception as e:
        import traceback
        update_ui_data('status', 'error')
        return {
            "success": False,
            "error": f"æ¤œç´¢å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {str(e)}\n\nè©³ç´°:\n{traceback.format_exc()}",
            "ui_info": ui_info
        }
    finally:
        if driver:
            try:
                driver.quit()
                message_callback("ãƒ–ãƒ©ã‚¦ã‚¶ã‚’çµ‚äº†ã—ã¾ã—ãŸ")
            except:
                pass
