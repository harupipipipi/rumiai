{
  "type": "ai_client_provider",
  "id": "ai_client_v1",
  "version": "1.0.0",
  "display_name": "AI Client Provider",
  "description": "複数のAIプロバイダー（Gemini、OpenAI、Anthropic等）を統合管理するクライアントシステム。",
  "entry": {
    "backend": "python:ai_client_loader",
    "frontend": null
  },
  "connectivity": {
    "accepts": [],
    "provides": [
      "ai_inference",
      "streaming",
      "function_calling_api"
    ],
    "requires": []
  },
  "storage": {
    "uses_mounts": [
      "data.cache"
    ],
    "layout": "component_defined"
  },
  "addon_policy": {
    "allowed_manifest_paths": [
      "/extensions"
    ],
    "editable_files": [
      {
        "path_glob": "ai_client/*/ai_profile/*.json",
        "allowed_json_pointer_prefixes": [
          "/benchmarks",
          "/metadata",
          "/extensions"
        ]
      }
    ],
    "deny_all": false
  },
  "extensions": {},
  "settings_schema": {
    "debug_logging": {
      "type": "boolean",
      "label": "デバッグログ",
      "description": "APIリクエスト/レスポンスをログファイルに記録します",
      "default": false
    },
    "default_temperature": {
      "type": "number",
      "label": "デフォルト温度",
      "description": "AI応答の温度パラメータのデフォルト値",
      "default": 0.7,
      "min": 0,
      "max": 2,
      "step": 0.1
    }
  },
  "metadata": {
    "supported_providers": [
      "gemini",
      "openai",
      "anthropic"
    ]
  }
}